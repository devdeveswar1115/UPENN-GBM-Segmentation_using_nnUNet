{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOmN0eHowDNZQiXadJZ6jOa"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vUaPQ615cGuY","executionInfo":{"status":"ok","timestamp":1748334959909,"user_tz":-330,"elapsed":22912,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"526029c8-7fb0-4758-9172-9a42d7c480e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":[],"metadata":{"id":"xYzMK7ViwGeE"}},{"cell_type":"code","source":["!pip install nnunetv2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"LHUm4uMmcX7L","executionInfo":{"status":"ok","timestamp":1748335074689,"user_tz":-330,"elapsed":112235,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"ca49ec8c-0ee3-499d-a977-7055ac8e4c35"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nnunetv2\n","  Downloading nnunetv2-2.6.0.tar.gz (206 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/206.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.3/206.3 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.6.0+cu124)\n","Collecting acvl-utils<0.3,>=0.2.3 (from nnunetv2)\n","  Downloading acvl_utils-0.2.5.tar.gz (29 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting dynamic-network-architectures<0.4,>=0.3.1 (from nnunetv2)\n","  Downloading dynamic_network_architectures-0.3.1.tar.gz (20 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (4.67.1)\n","Collecting dicom2nifti (from nnunetv2)\n","  Downloading dicom2nifti-2.6.1-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.15.3)\n","Collecting batchgenerators>=0.25.1 (from nnunetv2)\n","  Downloading batchgenerators-0.25.1.tar.gz (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.0.2)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (1.6.1)\n","Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.25.2)\n","Collecting SimpleITK>=2.2.1 (from nnunetv2)\n","  Downloading simpleitk-2.5.0-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.2.2)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.20.3)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2025.5.10)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (2.32.3)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (5.3.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.10.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.13.2)\n","Collecting imagecodecs (from nnunetv2)\n","  Downloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Collecting yacs (from nnunetv2)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Collecting batchgeneratorsv2>=0.2 (from nnunetv2)\n","  Downloading batchgeneratorsv2-0.2.3.tar.gz (35 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (0.8.1)\n","Requirement already satisfied: blosc2>=3.0.0b1 in /usr/local/lib/python3.11/dist-packages (from nnunetv2) (3.3.2)\n","Collecting connected-components-3d (from acvl-utils<0.3,>=0.2.3->nnunetv2)\n","  Downloading connected_components_3d-3.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (32 kB)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (11.2.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (1.0.0)\n","Collecting unittest2 (from batchgenerators>=0.25.1->nnunetv2)\n","  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from batchgenerators>=0.25.1->nnunetv2) (3.6.0)\n","Collecting fft-conv-pytorch (from batchgeneratorsv2>=0.2->nnunetv2)\n","  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: ndindex in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.9.2)\n","Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (1.1.0)\n","Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (4.3.8)\n","Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (2.10.2)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from blosc2>=3.0.0b1->nnunetv2) (9.0.0)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (3.4.2)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (2.37.0)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.19.3->nnunetv2) (0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (4.13.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.1.2->nnunetv2)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.1.2->nnunetv2)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.1.2->nnunetv2)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.1.2->nnunetv2)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.1.2->nnunetv2)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.1.2->nnunetv2)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.1.2->nnunetv2)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.1.2->nnunetv2) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.1.2->nnunetv2) (1.3.0)\n","Collecting pydicom>=3.0.0 (from dicom2nifti->nnunetv2)\n","  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n","Collecting python-gdcm (from dicom2nifti->nnunetv2)\n","  Downloading python_gdcm-3.0.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (4.58.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->nnunetv2) (2.9.0.post0)\n","Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel->nnunetv2) (6.5.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->nnunetv2) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->nnunetv2) (2025.4.26)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->nnunetv2) (1.5.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from yacs->nnunetv2) (6.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.1.2->nnunetv2) (3.0.2)\n","Collecting argparse (from unittest2->batchgenerators>=0.25.1->nnunetv2)\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n","Collecting traceback2 (from unittest2->batchgenerators>=0.25.1->nnunetv2)\n","  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25.1->nnunetv2)\n","  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\n","Downloading simpleitk-2.5.0-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dicom2nifti-2.6.1-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading imagecodecs-2025.3.30-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (45.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading connected_components_3d-3.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\n","Downloading python_gdcm-3.0.25-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n","Building wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, batchgeneratorsv2, dynamic-network-architectures\n","  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nnunetv2: filename=nnunetv2-2.6.0-py3-none-any.whl size=277015 sha256=c4139806cfd452934c6e3f5c9aebe94bfe153f14fd4ec2804d8625d8f279ad78\n","  Stored in directory: /root/.cache/pip/wheels/3d/0d/bb/f932cb0032d1aacc2f336de421448313d147db8eed671096e9\n","  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for acvl-utils: filename=acvl_utils-0.2.5-py3-none-any.whl size=27213 sha256=8d3453d8b9eda0e9fb77d36074902b88315ed921f5608a96858bd209036ae7e2\n","  Stored in directory: /root/.cache/pip/wheels/3f/8c/10/dcba79e0b2d1d463605233cec1fc6cfad47af5230b8985e464\n","  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for batchgenerators: filename=batchgenerators-0.25.1-py3-none-any.whl size=93088 sha256=02284469956d13d2a4fbf6d4d72896f4cfb1c69235df7613e7f6fd924edca5e0\n","  Stored in directory: /root/.cache/pip/wheels/56/11/c7/fadca30e054c602093ffe36ba8a2f0a87dd2f86ac75191d3ed\n","  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.2.3-py3-none-any.whl size=47567 sha256=e9d27b711a6700e0e725732866a474e7d2916068fd8f513875742c75e6cf05d8\n","  Stored in directory: /root/.cache/pip/wheels/1f/68/57/3a0eceb67b9c1b630df16113639b66a843dfd6686a4ed5ae1d\n","  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.3.1-py3-none-any.whl size=30048 sha256=aa307096603bfccbdd696d6a9923d36c1f26c7ed30f2c3dcef30ddc545c3b0ee\n","  Stored in directory: /root/.cache/pip/wheels/d9/8f/23/133ba252665b6f93abdbb294b323cc8fec041be83e4d22b701\n","Successfully built nnunetv2 acvl-utils batchgenerators batchgeneratorsv2 dynamic-network-architectures\n","Installing collected packages: SimpleITK, linecache2, argparse, yacs, traceback2, python-gdcm, pydicom, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, imagecodecs, connected-components-3d, unittest2, nvidia-cusparse-cu12, nvidia-cudnn-cu12, dicom2nifti, nvidia-cusolver-cu12, batchgenerators, fft-conv-pytorch, dynamic-network-architectures, acvl-utils, batchgeneratorsv2, nnunetv2\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed SimpleITK-2.5.0 acvl-utils-0.2.5 argparse-1.4.0 batchgenerators-0.25.1 batchgeneratorsv2-0.2.3 connected-components-3d-3.23.0 dicom2nifti-2.6.1 dynamic-network-architectures-0.3.1 fft-conv-pytorch-1.2.0 imagecodecs-2025.3.30 linecache2-1.0.0 nnunetv2-2.6.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydicom-3.0.1 python-gdcm-3.0.25 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]},"id":"e852e93f8a304e38a55b04680aebcfbc"}},"metadata":{}}]},{"cell_type":"code","source":["import os\n","os.environ['nnUNet_raw'] = \"/content/drive/MyDrive/TCIA/nnUNet/nnUNet_raw\"\n","os.environ['nnUNet_preprocessed'] =  \"/content/drive/MyDrive/TCIA/nnUNet/nnUNet_preprocessed\"\n","os.environ['nnUNet_results'] = \"/content/drive/MyDrive/TCIA/nnUNet/nnUNet_results\"\n","\n","# Verify dataset integrity has to be executed only the first time you are pre-processing the data\n","# After successful plan and preprocessing"],"metadata":{"id":"KTuZ906cdHJE","executionInfo":{"status":"ok","timestamp":1748335094615,"user_tz":-330,"elapsed":42,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!nnUNetv2_plan_and_preprocess -d 501 -c 3d_fullres --verify_dataset_integrity"],"metadata":{"id":"aRIZRmq3rXUj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727289102371,"user_tz":-330,"elapsed":273403,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"7102738d-4fd4-4c85-a59d-18ce3b77f9e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fingerprint extraction...\n","Dataset501_Glioblastoma\n","Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n","\n","####################\n","verify_dataset_integrity Done. \n","If you didn't see any error messages then your dataset is most likely OK!\n","####################\n","\n","Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n","100% 93/93 [00:25<00:00,  3.71it/s]\n","Experiment planning...\n","\n","############################\n","INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","Dropping 3d_lowres config because the image size difference to 3d_fullres is too small. 3d_fullres: [140. 172. 138.], 3d_lowres: [140, 172, 138]\n","2D U-Net configuration:\n","{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 105, 'patch_size': (192, 160), 'median_image_size_in_voxels': array([172., 138.]), 'spacing': array([1., 1.]), 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n","\n","Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> as reader/writer\n","3D fullres U-Net configuration:\n","{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (128, 128, 128), 'median_image_size_in_voxels': array([140., 172., 138.]), 'spacing': array([1., 1., 1.]), 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False}\n","\n","Plans were saved to /content/drive/MyDrive/TCIA/nnUNet/nnUNet_preprocessed/Dataset501_Glioblastoma/nnUNetPlans.json\n","Preprocessing...\n","Preprocessing dataset Dataset501_Glioblastoma\n","Configuration: 3d_fullres...\n","100% 93/93 [01:13<00:00,  1.27it/s]\n"]}]},{"cell_type":"code","source":["!pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-fyJU7rYi63r","executionInfo":{"status":"ok","timestamp":1728307917351,"user_tz":420,"elapsed":5679,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"517347f3-806a-45b6-a7b8-0a3788492afe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/FabianIsensee/hiddenlayer.git\n","  Cloning https://github.com/FabianIsensee/hiddenlayer.git to /tmp/pip-req-build-l0rbf1vl\n","  Running command git clone --filter=blob:none --quiet https://github.com/FabianIsensee/hiddenlayer.git /tmp/pip-req-build-l0rbf1vl\n","  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit b7263b6dc4569da1b6dea5964e1eac78fa32fa77\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: hiddenlayer\n","  Building wheel for hiddenlayer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hiddenlayer: filename=hiddenlayer-0.2-py3-none-any.whl size=20003 sha256=ee5401e0e8ae1104ee0ba7d3787735731a60c9f79085ac74077a78a251bacb16\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-r1ot_ex7/wheels/55/0e/e3/fdf2f92789305c0e320e0ab01f27fd4b757b1bb01c07d532c4\n","Successfully built hiddenlayer\n","Installing collected packages: hiddenlayer\n","Successfully installed hiddenlayer-0.2\n"]}]},{"cell_type":"code","source":["!pip install triton"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"750kMcc-kFlZ","executionInfo":{"status":"ok","timestamp":1727290976834,"user_tz":-330,"elapsed":11423,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"eaa90b93-6b00-4adb-feaf-f8dd9ca97204"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting triton\n","  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n","Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton\n","Successfully installed triton-3.0.0\n"]}]},{"cell_type":"code","source":["!export TORCH_LOGS=\"+dynamo\"\n","!export TORCHDYNAMO_VERBOSE=1"],"metadata":{"id":"UH3evOBXkKig"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade torch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yrMPmNN_kVBY","executionInfo":{"status":"ok","timestamp":1727291027087,"user_tz":-330,"elapsed":2553,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"7d109c80-a7a3-4e06-e323-e0cfa9c3a8c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"]}]},{"cell_type":"code","source":["!nnUNetv2_train Dataset501_Glioblastoma 3d_fullres 0 --npz"],"metadata":{"id":"7iJHwru3I9gj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1727293738546,"user_tz":-330,"elapsed":2702990,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"1ffc2427-49ca-4da3-ac3d-842db7dacae7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","############################\n","INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","Using device: cuda:0\n","/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n","\n","#######################################################################\n","Please cite the following paper when using nnU-Net:\n","Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n","#######################################################################\n","\n","2024-09-25 19:03:59.590067: do_dummy_2d_data_aug: False\n","2024-09-25 19:03:59.598333: Using splits from existing split file: /content/drive/MyDrive/TCIA/nnUNet/nnUNet_preprocessed/Dataset501_Glioblastoma/splits_final.json\n","2024-09-25 19:03:59.603715: The split file contains 5 splits.\n","2024-09-25 19:03:59.606379: Desired fold for training: 0\n","2024-09-25 19:03:59.609223: This split has 74 training and 19 validation cases.\n","using pin_memory on device 0\n","using pin_memory on device 0\n","2024-09-25 19:04:08.036837: Using torch.compile...\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n","\n","This is the configuration used by this training:\n","Configuration name: 3d_fullres\n"," {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [140.0, 172.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n","\n","These are the global plan.json settings:\n"," {'dataset_name': 'Dataset501_Glioblastoma', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [140, 172, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1464.0, 'mean': 334.0672607421875, 'median': 326.0, 'min': 0.0, 'percentile_00_5': 133.0, 'percentile_99_5': 995.0, 'std': 99.8768310546875}, '1': {'max': 2347.0, 'mean': 433.7585754394531, 'median': 384.0, 'min': 0.0, 'percentile_00_5': 148.0, 'percentile_99_5': 1267.0, 'std': 191.0032501220703}, '2': {'max': 2957.0, 'mean': 545.624267578125, 'median': 521.0, 'min': 0.0, 'percentile_00_5': 75.0, 'percentile_99_5': 1584.0, 'std': 356.63787841796875}, '3': {'max': 1535.0, 'mean': 403.13323974609375, 'median': 384.0, 'min': 0.0, 'percentile_00_5': 110.0, 'percentile_99_5': 942.0, 'std': 145.57351684570312}}} \n","\n","2024-09-25 19:04:10.330076: unpacking dataset...\n","2024-09-25 19:04:18.098408: unpacking done...\n","2024-09-25 19:04:18.121645: Unable to plot network architecture: nnUNet_compile is enabled!\n","2024-09-25 19:04:18.149399: \n","2024-09-25 19:04:18.152218: Epoch 0\n","2024-09-25 19:04:18.154408: Current learning rate: 0.01\n","W0925 19:04:33.389000 139145900069504 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 19:04:33.575000 139145900069504 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 19:04:33.661000 139145900069504 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 19:04:33.749000 139145900069504 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 19:04:33.837000 139145900069504 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 19:04:49.952000 139145900069504 torch/fx/experimental/symbolic_shapes.py:4449] [1/1] ps0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:04:56.534000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] d0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:04:57.052000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] d0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:04:57.363000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] d0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:04:57.676000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] d0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:04:59.240000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] d0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:00.622000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:00.681000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:01.261000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:01.323000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:01.606000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:01.663000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:01.932000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:01.991000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:03.711000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:03.862000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:04.971000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:05.314000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:05.508000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:05.712000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:06.696000 139141354186304 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x1 is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:47.342000 139145900069504 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:47.474000 139145900069504 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:47.547000 139145900069504 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:47.620000 139145900069504 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:47.696000 139145900069504 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 19:05:55.684000 139145900069504 torch/fx/experimental/symbolic_shapes.py:4449] [1/2] ps0 is not in var_ranges, defaulting to unknown range.\n","2024-09-25 19:06:00.520738: train_loss 0.0712\n","2024-09-25 19:06:00.526641: val_loss -0.2946\n","2024-09-25 19:06:00.549826: Pseudo dice [0.0, 0.7084, 0.661]\n","2024-09-25 19:06:00.559421: Epoch time: 102.37 s\n","2024-09-25 19:06:00.568265: Yayy! New best EMA pseudo Dice: 0.4565\n","2024-09-25 19:06:02.689333: \n","2024-09-25 19:06:02.692253: Epoch 1\n","2024-09-25 19:06:02.695354: Current learning rate: 0.00991\n","2024-09-25 19:06:24.923485: train_loss -0.3785\n","2024-09-25 19:06:24.932668: val_loss -0.4003\n","2024-09-25 19:06:24.938878: Pseudo dice [0.3148, 0.7055, 0.6791]\n","2024-09-25 19:06:24.945779: Epoch time: 22.24 s\n","2024-09-25 19:06:24.951856: Yayy! New best EMA pseudo Dice: 0.4675\n","2024-09-25 19:06:27.237843: \n","2024-09-25 19:06:27.241230: Epoch 2\n","2024-09-25 19:06:27.244216: Current learning rate: 0.00982\n","2024-09-25 19:06:49.427535: train_loss -0.3937\n","2024-09-25 19:06:49.434187: val_loss -0.4367\n","2024-09-25 19:06:49.440583: Pseudo dice [0.3835, 0.713, 0.6847]\n","2024-09-25 19:06:49.446573: Epoch time: 22.19 s\n","2024-09-25 19:06:49.452844: Yayy! New best EMA pseudo Dice: 0.4801\n","2024-09-25 19:06:52.133587: \n","2024-09-25 19:06:52.136935: Epoch 3\n","2024-09-25 19:06:52.140465: Current learning rate: 0.00973\n","2024-09-25 19:07:14.327679: train_loss -0.4841\n","2024-09-25 19:07:14.339293: val_loss -0.4532\n","2024-09-25 19:07:14.361913: Pseudo dice [0.4849, 0.7069, 0.6743]\n","2024-09-25 19:07:14.371770: Epoch time: 22.2 s\n","2024-09-25 19:07:14.381655: Yayy! New best EMA pseudo Dice: 0.4943\n","2024-09-25 19:07:16.750870: \n","2024-09-25 19:07:16.754671: Epoch 4\n","2024-09-25 19:07:16.759192: Current learning rate: 0.00964\n","2024-09-25 19:07:39.121960: train_loss -0.5434\n","2024-09-25 19:07:39.129369: val_loss -0.4887\n","2024-09-25 19:07:39.134483: Pseudo dice [0.6049, 0.7326, 0.6506]\n","2024-09-25 19:07:39.140135: Epoch time: 22.37 s\n","2024-09-25 19:07:39.145220: Yayy! New best EMA pseudo Dice: 0.5111\n","2024-09-25 19:07:41.587097: \n","2024-09-25 19:07:41.589900: Epoch 5\n","2024-09-25 19:07:41.592087: Current learning rate: 0.00955\n","2024-09-25 19:08:04.949505: train_loss -0.5888\n","2024-09-25 19:08:04.954586: val_loss -0.5228\n","2024-09-25 19:08:04.959594: Pseudo dice [0.5954, 0.7561, 0.7001]\n","2024-09-25 19:08:04.964547: Epoch time: 23.36 s\n","2024-09-25 19:08:04.983258: Yayy! New best EMA pseudo Dice: 0.5284\n","2024-09-25 19:08:07.306350: \n","2024-09-25 19:08:07.309208: Epoch 6\n","2024-09-25 19:08:07.311458: Current learning rate: 0.00946\n","2024-09-25 19:08:30.024760: train_loss -0.565\n","2024-09-25 19:08:30.034423: val_loss -0.4915\n","2024-09-25 19:08:30.040898: Pseudo dice [0.6076, 0.7488, 0.7018]\n","2024-09-25 19:08:30.049848: Epoch time: 22.72 s\n","2024-09-25 19:08:30.059216: Yayy! New best EMA pseudo Dice: 0.5442\n","2024-09-25 19:08:32.541785: \n","2024-09-25 19:08:32.544823: Epoch 7\n","2024-09-25 19:08:32.547000: Current learning rate: 0.00937\n","2024-09-25 19:08:54.778060: train_loss -0.6051\n","2024-09-25 19:08:54.782752: val_loss -0.588\n","2024-09-25 19:08:54.787693: Pseudo dice [0.7151, 0.7803, 0.7386]\n","2024-09-25 19:08:54.792161: Epoch time: 22.24 s\n","2024-09-25 19:08:54.798581: Yayy! New best EMA pseudo Dice: 0.5642\n","2024-09-25 19:08:57.200282: \n","2024-09-25 19:08:57.203669: Epoch 8\n","2024-09-25 19:08:57.481802: Current learning rate: 0.00928\n","2024-09-25 19:09:19.947603: train_loss -0.6101\n","2024-09-25 19:09:19.958365: val_loss -0.5168\n","2024-09-25 19:09:19.967988: Pseudo dice [0.6745, 0.7221, 0.6738]\n","2024-09-25 19:09:19.976028: Epoch time: 22.75 s\n","2024-09-25 19:09:19.983741: Yayy! New best EMA pseudo Dice: 0.5768\n","2024-09-25 19:09:22.586771: \n","2024-09-25 19:09:22.589481: Epoch 9\n","2024-09-25 19:09:22.591644: Current learning rate: 0.00919\n","2024-09-25 19:09:45.152058: train_loss -0.6305\n","2024-09-25 19:09:45.157149: val_loss -0.6046\n","2024-09-25 19:09:45.162002: Pseudo dice [0.7041, 0.7998, 0.7466]\n","2024-09-25 19:09:45.166750: Epoch time: 22.57 s\n","2024-09-25 19:09:45.171125: Yayy! New best EMA pseudo Dice: 0.5942\n","2024-09-25 19:09:47.516862: \n","2024-09-25 19:09:47.519705: Epoch 10\n","2024-09-25 19:09:47.522795: Current learning rate: 0.0091\n","2024-09-25 19:10:10.021369: train_loss -0.6666\n","2024-09-25 19:10:10.026932: val_loss -0.5981\n","2024-09-25 19:10:10.033335: Pseudo dice [0.6593, 0.7675, 0.7234]\n","2024-09-25 19:10:10.039330: Epoch time: 22.51 s\n","2024-09-25 19:10:10.044246: Yayy! New best EMA pseudo Dice: 0.6064\n","2024-09-25 19:10:12.487284: \n","2024-09-25 19:10:12.491109: Epoch 11\n","2024-09-25 19:10:12.494132: Current learning rate: 0.009\n","2024-09-25 19:10:34.887036: train_loss -0.6801\n","2024-09-25 19:10:34.907607: val_loss -0.6049\n","2024-09-25 19:10:34.912077: Pseudo dice [0.7105, 0.793, 0.7174]\n","2024-09-25 19:10:34.917309: Epoch time: 22.4 s\n","2024-09-25 19:10:34.922711: Yayy! New best EMA pseudo Dice: 0.6198\n","2024-09-25 19:10:37.256477: \n","2024-09-25 19:10:37.259388: Epoch 12\n","2024-09-25 19:10:37.261702: Current learning rate: 0.00891\n","2024-09-25 19:10:59.789815: train_loss -0.6648\n","2024-09-25 19:10:59.796339: val_loss -0.5786\n","2024-09-25 19:10:59.802449: Pseudo dice [0.585, 0.8419, 0.7389]\n","2024-09-25 19:10:59.810072: Epoch time: 22.53 s\n","2024-09-25 19:10:59.817912: Yayy! New best EMA pseudo Dice: 0.63\n","2024-09-25 19:11:02.130961: \n","2024-09-25 19:11:02.134085: Epoch 13\n","2024-09-25 19:11:02.136353: Current learning rate: 0.00882\n","2024-09-25 19:11:24.787004: train_loss -0.6646\n","2024-09-25 19:11:24.796354: val_loss -0.6684\n","2024-09-25 19:11:24.806312: Pseudo dice [0.7511, 0.8236, 0.7913]\n","2024-09-25 19:11:24.815701: Epoch time: 22.66 s\n","2024-09-25 19:11:24.824578: Yayy! New best EMA pseudo Dice: 0.6459\n","2024-09-25 19:11:27.444754: \n","2024-09-25 19:11:28.077948: Epoch 14\n","2024-09-25 19:11:28.081840: Current learning rate: 0.00873\n","2024-09-25 19:11:50.597009: train_loss -0.684\n","2024-09-25 19:11:50.604153: val_loss -0.6481\n","2024-09-25 19:11:50.611214: Pseudo dice [0.7241, 0.8495, 0.772]\n","2024-09-25 19:11:50.618300: Epoch time: 23.15 s\n","2024-09-25 19:11:50.624667: Yayy! New best EMA pseudo Dice: 0.6595\n","2024-09-25 19:11:53.063818: \n","2024-09-25 19:11:53.066957: Epoch 15\n","2024-09-25 19:11:53.071954: Current learning rate: 0.00864\n","2024-09-25 19:12:15.609657: train_loss -0.6693\n","2024-09-25 19:12:15.616826: val_loss -0.6799\n","2024-09-25 19:12:15.621787: Pseudo dice [0.7447, 0.8569, 0.7755]\n","2024-09-25 19:12:15.628351: Epoch time: 22.55 s\n","2024-09-25 19:12:15.634696: Yayy! New best EMA pseudo Dice: 0.6728\n","2024-09-25 19:12:18.618387: \n","2024-09-25 19:12:18.621370: Epoch 16\n","2024-09-25 19:12:18.624399: Current learning rate: 0.00855\n","2024-09-25 19:12:41.238312: train_loss -0.6895\n","2024-09-25 19:12:41.258215: val_loss -0.7025\n","2024-09-25 19:12:41.266262: Pseudo dice [0.7938, 0.8496, 0.8235]\n","2024-09-25 19:12:41.275925: Epoch time: 22.62 s\n","2024-09-25 19:12:41.283337: Yayy! New best EMA pseudo Dice: 0.6877\n","2024-09-25 19:12:44.820754: \n","2024-09-25 19:12:44.824017: Epoch 17\n","2024-09-25 19:12:44.827313: Current learning rate: 0.00846\n","2024-09-25 19:13:07.404745: train_loss -0.6952\n","2024-09-25 19:13:07.411167: val_loss -0.6681\n","2024-09-25 19:13:07.417253: Pseudo dice [0.6825, 0.8046, 0.7772]\n","2024-09-25 19:13:07.423553: Epoch time: 22.59 s\n","2024-09-25 19:13:07.428819: Yayy! New best EMA pseudo Dice: 0.6944\n","2024-09-25 19:13:09.837175: \n","2024-09-25 19:13:09.840148: Epoch 18\n","2024-09-25 19:13:09.843772: Current learning rate: 0.00836\n","2024-09-25 19:13:32.477427: train_loss -0.6965\n","2024-09-25 19:13:32.483985: val_loss -0.6344\n","2024-09-25 19:13:32.490190: Pseudo dice [0.6015, 0.8183, 0.8011]\n","2024-09-25 19:13:32.495131: Epoch time: 22.64 s\n","2024-09-25 19:13:32.499379: Yayy! New best EMA pseudo Dice: 0.699\n","2024-09-25 19:13:34.923933: \n","2024-09-25 19:13:35.552459: Epoch 19\n","2024-09-25 19:13:35.555793: Current learning rate: 0.00827\n","2024-09-25 19:13:58.137134: train_loss -0.7082\n","2024-09-25 19:13:58.143942: val_loss -0.6598\n","2024-09-25 19:13:58.152348: Pseudo dice [0.6931, 0.8083, 0.8197]\n","2024-09-25 19:13:58.160177: Epoch time: 23.21 s\n","2024-09-25 19:13:58.166130: Yayy! New best EMA pseudo Dice: 0.7065\n","2024-09-25 19:14:00.629232: \n","2024-09-25 19:14:00.632702: Epoch 20\n","2024-09-25 19:14:00.634886: Current learning rate: 0.00818\n","2024-09-25 19:14:23.133868: train_loss -0.7239\n","2024-09-25 19:14:23.143238: val_loss -0.7027\n","2024-09-25 19:14:23.148530: Pseudo dice [0.7752, 0.8549, 0.8087]\n","2024-09-25 19:14:23.154713: Epoch time: 22.51 s\n","2024-09-25 19:14:23.177561: Yayy! New best EMA pseudo Dice: 0.7171\n","2024-09-25 19:14:25.618468: \n","2024-09-25 19:14:25.621376: Epoch 21\n","2024-09-25 19:14:25.623577: Current learning rate: 0.00809\n","2024-09-25 19:14:48.197266: train_loss -0.7188\n","2024-09-25 19:14:48.204599: val_loss -0.6582\n","2024-09-25 19:14:48.211579: Pseudo dice [0.7272, 0.8566, 0.7611]\n","2024-09-25 19:14:48.218455: Epoch time: 22.58 s\n","2024-09-25 19:14:48.226230: Yayy! New best EMA pseudo Dice: 0.7236\n","2024-09-25 19:14:50.630467: \n","2024-09-25 19:14:50.633768: Epoch 22\n","2024-09-25 19:14:50.636567: Current learning rate: 0.008\n","2024-09-25 19:15:13.056601: train_loss -0.7057\n","2024-09-25 19:15:13.077152: val_loss -0.6892\n","2024-09-25 19:15:13.081807: Pseudo dice [0.7686, 0.8625, 0.8017]\n","2024-09-25 19:15:13.086872: Epoch time: 22.43 s\n","2024-09-25 19:15:13.091578: Yayy! New best EMA pseudo Dice: 0.7323\n","2024-09-25 19:15:15.387434: \n","2024-09-25 19:15:15.390822: Epoch 23\n","2024-09-25 19:15:15.395113: Current learning rate: 0.0079\n","2024-09-25 19:15:37.952197: train_loss -0.7064\n","2024-09-25 19:15:37.959102: val_loss -0.6615\n","2024-09-25 19:15:37.965410: Pseudo dice [0.7662, 0.8271, 0.7643]\n","2024-09-25 19:15:37.971908: Epoch time: 22.57 s\n","2024-09-25 19:15:37.978256: Yayy! New best EMA pseudo Dice: 0.7377\n","2024-09-25 19:15:40.327098: \n","2024-09-25 19:15:40.330469: Epoch 24\n","2024-09-25 19:15:40.963412: Current learning rate: 0.00781\n","2024-09-25 19:16:03.559603: train_loss -0.7315\n","2024-09-25 19:16:03.573685: val_loss -0.6594\n","2024-09-25 19:16:03.582508: Pseudo dice [0.7717, 0.7978, 0.7974]\n","2024-09-25 19:16:03.588986: Epoch time: 23.23 s\n","2024-09-25 19:16:03.596131: Yayy! New best EMA pseudo Dice: 0.7428\n","2024-09-25 19:16:06.087731: \n","2024-09-25 19:16:06.090341: Epoch 25\n","2024-09-25 19:16:06.093232: Current learning rate: 0.00772\n","2024-09-25 19:16:28.636886: train_loss -0.7\n","2024-09-25 19:16:28.643729: val_loss -0.6791\n","2024-09-25 19:16:28.650179: Pseudo dice [0.7582, 0.8727, 0.785]\n","2024-09-25 19:16:28.656225: Epoch time: 22.55 s\n","2024-09-25 19:16:28.662151: Yayy! New best EMA pseudo Dice: 0.7491\n","2024-09-25 19:16:30.994161: \n","2024-09-25 19:16:30.997107: Epoch 26\n","2024-09-25 19:16:31.000271: Current learning rate: 0.00763\n","2024-09-25 19:16:53.653782: train_loss -0.7169\n","2024-09-25 19:16:53.660343: val_loss -0.6848\n","2024-09-25 19:16:53.665369: Pseudo dice [0.7666, 0.8318, 0.78]\n","2024-09-25 19:16:53.683957: Epoch time: 22.66 s\n","2024-09-25 19:16:53.690101: Yayy! New best EMA pseudo Dice: 0.7534\n","2024-09-25 19:16:56.107214: \n","2024-09-25 19:16:56.110437: Epoch 27\n","2024-09-25 19:16:56.114017: Current learning rate: 0.00753\n","2024-09-25 19:17:18.646850: train_loss -0.7387\n","2024-09-25 19:17:18.653897: val_loss -0.6782\n","2024-09-25 19:17:18.664326: Pseudo dice [0.7605, 0.8504, 0.7743]\n","2024-09-25 19:17:18.674178: Epoch time: 22.54 s\n","2024-09-25 19:17:18.684007: Yayy! New best EMA pseudo Dice: 0.7576\n","2024-09-25 19:17:21.333307: \n","2024-09-25 19:17:21.336481: Epoch 28\n","2024-09-25 19:17:21.339128: Current learning rate: 0.00744\n","2024-09-25 19:17:43.939678: train_loss -0.7364\n","2024-09-25 19:17:43.946807: val_loss -0.6986\n","2024-09-25 19:17:43.952758: Pseudo dice [0.8276, 0.8608, 0.8129]\n","2024-09-25 19:17:43.958230: Epoch time: 22.61 s\n","2024-09-25 19:17:43.963306: Yayy! New best EMA pseudo Dice: 0.7652\n","2024-09-25 19:17:46.266138: \n","2024-09-25 19:17:46.269002: Epoch 29\n","2024-09-25 19:17:46.272029: Current learning rate: 0.00735\n","2024-09-25 19:18:08.990616: train_loss -0.7219\n","2024-09-25 19:18:08.999028: val_loss -0.6816\n","2024-09-25 19:18:09.009282: Pseudo dice [0.8137, 0.8358, 0.7959]\n","2024-09-25 19:18:09.018898: Epoch time: 22.73 s\n","2024-09-25 19:18:09.024731: Yayy! New best EMA pseudo Dice: 0.7702\n","2024-09-25 19:18:11.445371: \n","2024-09-25 19:18:12.078495: Epoch 30\n","2024-09-25 19:18:12.080890: Current learning rate: 0.00725\n","2024-09-25 19:18:34.525039: train_loss -0.7252\n","2024-09-25 19:18:34.532471: val_loss -0.7254\n","2024-09-25 19:18:34.541795: Pseudo dice [0.8349, 0.8683, 0.8205]\n","2024-09-25 19:18:34.551349: Epoch time: 23.08 s\n","2024-09-25 19:18:34.562422: Yayy! New best EMA pseudo Dice: 0.7773\n","2024-09-25 19:18:36.999834: \n","2024-09-25 19:18:37.003236: Epoch 31\n","2024-09-25 19:18:37.005985: Current learning rate: 0.00716\n","2024-09-25 19:18:59.438085: train_loss -0.72\n","2024-09-25 19:18:59.443213: val_loss -0.7385\n","2024-09-25 19:18:59.449696: Pseudo dice [0.8354, 0.8595, 0.8153]\n","2024-09-25 19:18:59.455946: Epoch time: 22.44 s\n","2024-09-25 19:18:59.461730: Yayy! New best EMA pseudo Dice: 0.7832\n","2024-09-25 19:19:01.873039: \n","2024-09-25 19:19:01.875924: Epoch 32\n","2024-09-25 19:19:01.878888: Current learning rate: 0.00707\n","2024-09-25 19:19:24.366351: train_loss -0.7379\n","2024-09-25 19:19:24.371494: val_loss -0.6946\n","2024-09-25 19:19:24.376641: Pseudo dice [0.8043, 0.8584, 0.7892]\n","2024-09-25 19:19:24.380940: Epoch time: 22.49 s\n","2024-09-25 19:19:24.384892: Yayy! New best EMA pseudo Dice: 0.7866\n","2024-09-25 19:19:26.683718: \n","2024-09-25 19:19:26.686701: Epoch 33\n","2024-09-25 19:19:26.689112: Current learning rate: 0.00697\n","2024-09-25 19:19:49.224828: train_loss -0.7477\n","2024-09-25 19:19:49.233001: val_loss -0.6571\n","2024-09-25 19:19:49.241659: Pseudo dice [0.7283, 0.843, 0.7939]\n","2024-09-25 19:19:49.248824: Epoch time: 22.54 s\n","2024-09-25 19:19:49.255549: Yayy! New best EMA pseudo Dice: 0.7868\n","2024-09-25 19:19:51.692511: \n","2024-09-25 19:19:51.695308: Epoch 34\n","2024-09-25 19:19:51.698408: Current learning rate: 0.00688\n","2024-09-25 19:20:14.176467: train_loss -0.7544\n","2024-09-25 19:20:14.182351: val_loss -0.6645\n","2024-09-25 19:20:14.189595: Pseudo dice [0.7798, 0.8597, 0.7682]\n","2024-09-25 19:20:14.206724: Epoch time: 22.49 s\n","2024-09-25 19:20:14.213089: Yayy! New best EMA pseudo Dice: 0.7884\n","2024-09-25 19:20:17.387890: \n","2024-09-25 19:20:17.391054: Epoch 35\n","2024-09-25 19:20:17.394453: Current learning rate: 0.00679\n","2024-09-25 19:20:39.978987: train_loss -0.7514\n","2024-09-25 19:20:39.986369: val_loss -0.7285\n","2024-09-25 19:20:39.994090: Pseudo dice [0.7793, 0.8766, 0.8325]\n","2024-09-25 19:20:40.002071: Epoch time: 22.59 s\n","2024-09-25 19:20:40.020227: Yayy! New best EMA pseudo Dice: 0.7925\n","2024-09-25 19:20:42.781367: \n","2024-09-25 19:20:42.785037: Epoch 36\n","2024-09-25 19:20:42.800642: Current learning rate: 0.00669\n","2024-09-25 19:21:05.250199: train_loss -0.7556\n","2024-09-25 19:21:05.258636: val_loss -0.7217\n","2024-09-25 19:21:05.266517: Pseudo dice [0.8163, 0.8454, 0.8206]\n","2024-09-25 19:21:05.272140: Epoch time: 22.47 s\n","2024-09-25 19:21:05.280671: Yayy! New best EMA pseudo Dice: 0.796\n","2024-09-25 19:21:07.752508: \n","2024-09-25 19:21:07.756405: Epoch 37\n","2024-09-25 19:21:07.758806: Current learning rate: 0.0066\n","2024-09-25 19:21:30.253859: train_loss -0.7544\n","2024-09-25 19:21:30.258816: val_loss -0.6732\n","2024-09-25 19:21:30.263481: Pseudo dice [0.7735, 0.8531, 0.8027]\n","2024-09-25 19:21:30.267707: Epoch time: 22.5 s\n","2024-09-25 19:21:30.285036: Yayy! New best EMA pseudo Dice: 0.7974\n","2024-09-25 19:21:32.632142: \n","2024-09-25 19:21:32.634965: Epoch 38\n","2024-09-25 19:21:32.637032: Current learning rate: 0.0065\n","2024-09-25 19:21:55.138615: train_loss -0.7616\n","2024-09-25 19:21:55.145139: val_loss -0.6832\n","2024-09-25 19:21:55.151292: Pseudo dice [0.774, 0.845, 0.7981]\n","2024-09-25 19:21:55.157736: Epoch time: 22.51 s\n","2024-09-25 19:21:55.162549: Yayy! New best EMA pseudo Dice: 0.7982\n","2024-09-25 19:21:57.619649: \n","2024-09-25 19:21:57.622472: Epoch 39\n","2024-09-25 19:21:57.625569: Current learning rate: 0.00641\n","2024-09-25 19:22:20.102672: train_loss -0.7503\n","2024-09-25 19:22:20.112528: val_loss -0.7308\n","2024-09-25 19:22:20.120245: Pseudo dice [0.8348, 0.8563, 0.8343]\n","2024-09-25 19:22:20.143024: Epoch time: 22.48 s\n","2024-09-25 19:22:20.149766: Yayy! New best EMA pseudo Dice: 0.8026\n","2024-09-25 19:22:22.610094: \n","2024-09-25 19:22:22.613021: Epoch 40\n","2024-09-25 19:22:22.616328: Current learning rate: 0.00631\n","2024-09-25 19:22:45.319307: train_loss -0.7385\n","2024-09-25 19:22:45.325853: val_loss -0.7169\n","2024-09-25 19:22:45.332257: Pseudo dice [0.7816, 0.8705, 0.8102]\n","2024-09-25 19:22:45.338819: Epoch time: 22.71 s\n","2024-09-25 19:22:45.348321: Yayy! New best EMA pseudo Dice: 0.8044\n","2024-09-25 19:22:47.994263: \n","2024-09-25 19:22:47.997564: Epoch 41\n","2024-09-25 19:22:48.001219: Current learning rate: 0.00622\n","2024-09-25 19:23:10.756813: train_loss -0.7578\n","2024-09-25 19:23:10.766519: val_loss -0.7049\n","2024-09-25 19:23:10.775056: Pseudo dice [0.7829, 0.8723, 0.7767]\n","2024-09-25 19:23:10.781982: Epoch time: 22.76 s\n","2024-09-25 19:23:10.813580: Yayy! New best EMA pseudo Dice: 0.805\n","2024-09-25 19:23:13.352470: \n","2024-09-25 19:23:13.615902: Epoch 42\n","2024-09-25 19:23:13.618854: Current learning rate: 0.00612\n","2024-09-25 19:23:36.391483: train_loss -0.7466\n","2024-09-25 19:23:36.399600: val_loss -0.7033\n","2024-09-25 19:23:36.416299: Pseudo dice [0.7879, 0.8604, 0.8032]\n","2024-09-25 19:23:36.432153: Epoch time: 23.04 s\n","2024-09-25 19:23:36.439694: Yayy! New best EMA pseudo Dice: 0.8062\n","2024-09-25 19:23:38.885210: \n","2024-09-25 19:23:38.888162: Epoch 43\n","2024-09-25 19:23:38.890285: Current learning rate: 0.00603\n","2024-09-25 19:24:01.618605: train_loss -0.762\n","2024-09-25 19:24:01.628475: val_loss -0.6923\n","2024-09-25 19:24:01.636377: Pseudo dice [0.7682, 0.8708, 0.7987]\n","2024-09-25 19:24:01.643946: Epoch time: 22.73 s\n","2024-09-25 19:24:01.662911: Yayy! New best EMA pseudo Dice: 0.8069\n","2024-09-25 19:24:03.973409: \n","2024-09-25 19:24:03.976143: Epoch 44\n","2024-09-25 19:24:03.979049: Current learning rate: 0.00593\n","2024-09-25 19:24:26.827429: train_loss -0.734\n","2024-09-25 19:24:26.834421: val_loss -0.6609\n","2024-09-25 19:24:26.842201: Pseudo dice [0.727, 0.8655, 0.7591]\n","2024-09-25 19:24:26.849320: Epoch time: 22.86 s\n","2024-09-25 19:24:28.542807: \n","2024-09-25 19:24:28.545811: Epoch 45\n","2024-09-25 19:24:28.549123: Current learning rate: 0.00584\n","2024-09-25 19:24:51.144968: train_loss -0.7526\n","2024-09-25 19:24:51.151232: val_loss -0.7055\n","2024-09-25 19:24:51.159212: Pseudo dice [0.7896, 0.8422, 0.7959]\n","2024-09-25 19:24:51.167884: Epoch time: 22.6 s\n","2024-09-25 19:24:52.789101: \n","2024-09-25 19:24:52.792160: Epoch 46\n","2024-09-25 19:24:52.794321: Current learning rate: 0.00574\n","2024-09-25 19:25:15.408385: train_loss -0.7481\n","2024-09-25 19:25:15.420283: val_loss -0.689\n","2024-09-25 19:25:15.432032: Pseudo dice [0.7697, 0.8574, 0.7936]\n","2024-09-25 19:25:15.443605: Epoch time: 22.62 s\n","2024-09-25 19:25:17.144781: \n","2024-09-25 19:25:17.147823: Epoch 47\n","2024-09-25 19:25:17.150269: Current learning rate: 0.00565\n","2024-09-25 19:25:39.841857: train_loss -0.7489\n","2024-09-25 19:25:39.848545: val_loss -0.7042\n","2024-09-25 19:25:39.857182: Pseudo dice [0.8307, 0.8768, 0.8202]\n","2024-09-25 19:25:39.862092: Epoch time: 22.7 s\n","2024-09-25 19:25:39.869037: Yayy! New best EMA pseudo Dice: 0.809\n","2024-09-25 19:25:42.145249: \n","2024-09-25 19:25:42.148199: Epoch 48\n","2024-09-25 19:25:42.151269: Current learning rate: 0.00555\n","2024-09-25 19:26:04.808712: train_loss -0.7327\n","2024-09-25 19:26:04.815167: val_loss -0.678\n","2024-09-25 19:26:04.823320: Pseudo dice [0.6957, 0.8354, 0.8035]\n","2024-09-25 19:26:04.830074: Epoch time: 22.66 s\n","2024-09-25 19:26:06.396737: \n","2024-09-25 19:26:06.399683: Epoch 49\n","2024-09-25 19:26:06.402824: Current learning rate: 0.00546\n","2024-09-25 19:26:28.935438: train_loss -0.7613\n","2024-09-25 19:26:28.942357: val_loss -0.6675\n","2024-09-25 19:26:28.948275: Pseudo dice [0.8047, 0.8731, 0.7599]\n","2024-09-25 19:26:28.956868: Epoch time: 22.54 s\n","2024-09-25 19:26:31.373916: \n","2024-09-25 19:26:31.377071: Epoch 50\n","2024-09-25 19:26:31.379176: Current learning rate: 0.00536\n","2024-09-25 19:26:53.987931: train_loss -0.7667\n","2024-09-25 19:26:53.996429: val_loss -0.7356\n","2024-09-25 19:26:54.004724: Pseudo dice [0.8136, 0.8814, 0.8286]\n","2024-09-25 19:26:54.012865: Epoch time: 22.62 s\n","2024-09-25 19:26:54.022094: Yayy! New best EMA pseudo Dice: 0.81\n","2024-09-25 19:26:56.379274: \n","2024-09-25 19:26:56.382119: Epoch 51\n","2024-09-25 19:26:56.385254: Current learning rate: 0.00526\n","2024-09-25 19:27:18.908671: train_loss -0.7768\n","2024-09-25 19:27:18.915296: val_loss -0.702\n","2024-09-25 19:27:18.923380: Pseudo dice [0.8037, 0.8565, 0.8042]\n","2024-09-25 19:27:18.932775: Epoch time: 22.53 s\n","2024-09-25 19:27:18.941042: Yayy! New best EMA pseudo Dice: 0.8112\n","2024-09-25 19:27:21.389595: \n","2024-09-25 19:27:21.392555: Epoch 52\n","2024-09-25 19:27:21.395705: Current learning rate: 0.00517\n","2024-09-25 19:27:43.919744: train_loss -0.7342\n","2024-09-25 19:27:43.925501: val_loss -0.7199\n","2024-09-25 19:27:43.931881: Pseudo dice [0.8151, 0.8762, 0.8042]\n","2024-09-25 19:27:43.950783: Epoch time: 22.53 s\n","2024-09-25 19:27:43.956325: Yayy! New best EMA pseudo Dice: 0.8132\n","2024-09-25 19:27:46.322086: \n","2024-09-25 19:27:46.325228: Epoch 53\n","2024-09-25 19:27:46.328442: Current learning rate: 0.00507\n","2024-09-25 19:28:08.900123: train_loss -0.7607\n","2024-09-25 19:28:08.906121: val_loss -0.6498\n","2024-09-25 19:28:08.912285: Pseudo dice [0.762, 0.8618, 0.7655]\n","2024-09-25 19:28:08.919342: Epoch time: 22.58 s\n","2024-09-25 19:28:10.463905: \n","2024-09-25 19:28:10.466715: Epoch 54\n","2024-09-25 19:28:10.468763: Current learning rate: 0.00497\n","2024-09-25 19:28:32.985066: train_loss -0.7568\n","2024-09-25 19:28:32.992050: val_loss -0.6869\n","2024-09-25 19:28:32.996344: Pseudo dice [0.8042, 0.8552, 0.7988]\n","2024-09-25 19:28:33.003424: Epoch time: 22.52 s\n","2024-09-25 19:28:35.474844: \n","2024-09-25 19:28:35.477831: Epoch 55\n","2024-09-25 19:28:35.481019: Current learning rate: 0.00487\n","2024-09-25 19:28:58.075689: train_loss -0.749\n","2024-09-25 19:28:58.084563: val_loss -0.7127\n","2024-09-25 19:28:58.089970: Pseudo dice [0.8044, 0.8555, 0.8063]\n","2024-09-25 19:28:58.095317: Epoch time: 22.6 s\n","2024-09-25 19:28:58.101434: Yayy! New best EMA pseudo Dice: 0.8133\n","2024-09-25 19:29:00.448609: \n","2024-09-25 19:29:00.451529: Epoch 56\n","2024-09-25 19:29:00.454572: Current learning rate: 0.00478\n","2024-09-25 19:29:23.111775: train_loss -0.7656\n","2024-09-25 19:29:23.117529: val_loss -0.7217\n","2024-09-25 19:29:23.123157: Pseudo dice [0.7949, 0.8875, 0.8074]\n","2024-09-25 19:29:23.127993: Epoch time: 22.66 s\n","2024-09-25 19:29:23.132292: Yayy! New best EMA pseudo Dice: 0.815\n","2024-09-25 19:29:25.515467: \n","2024-09-25 19:29:25.518440: Epoch 57\n","2024-09-25 19:29:25.520582: Current learning rate: 0.00468\n","2024-09-25 19:29:48.680673: train_loss -0.7585\n","2024-09-25 19:29:48.687261: val_loss -0.7348\n","2024-09-25 19:29:48.710722: Pseudo dice [0.8339, 0.8813, 0.8302]\n","2024-09-25 19:29:48.718102: Epoch time: 23.17 s\n","2024-09-25 19:29:48.723158: Yayy! New best EMA pseudo Dice: 0.8183\n","2024-09-25 19:29:51.438808: \n","2024-09-25 19:29:51.441747: Epoch 58\n","2024-09-25 19:29:51.443909: Current learning rate: 0.00458\n","2024-09-25 19:30:14.738069: train_loss -0.7629\n","2024-09-25 19:30:14.746305: val_loss -0.7091\n","2024-09-25 19:30:14.753204: Pseudo dice [0.7569, 0.8726, 0.8028]\n","2024-09-25 19:30:14.758266: Epoch time: 23.3 s\n","2024-09-25 19:30:16.459093: \n","2024-09-25 19:30:16.462524: Epoch 59\n","2024-09-25 19:30:16.464900: Current learning rate: 0.00448\n","2024-09-25 19:30:39.071751: train_loss -0.7664\n","2024-09-25 19:30:39.080582: val_loss -0.7424\n","2024-09-25 19:30:39.086695: Pseudo dice [0.8378, 0.8638, 0.8299]\n","2024-09-25 19:30:39.094530: Epoch time: 22.61 s\n","2024-09-25 19:30:39.102202: Yayy! New best EMA pseudo Dice: 0.8202\n","2024-09-25 19:30:42.118017: \n","2024-09-25 19:30:42.121065: Epoch 60\n","2024-09-25 19:30:42.124284: Current learning rate: 0.00438\n","2024-09-25 19:31:04.693267: train_loss -0.7648\n","2024-09-25 19:31:04.699179: val_loss -0.6938\n","2024-09-25 19:31:04.706086: Pseudo dice [0.8046, 0.8424, 0.7921]\n","2024-09-25 19:31:04.712857: Epoch time: 22.58 s\n","2024-09-25 19:31:06.290044: \n","2024-09-25 19:31:06.293529: Epoch 61\n","2024-09-25 19:31:06.295930: Current learning rate: 0.00429\n","2024-09-25 19:31:28.925936: train_loss -0.7871\n","2024-09-25 19:31:28.934643: val_loss -0.7133\n","2024-09-25 19:31:28.944032: Pseudo dice [0.8352, 0.8625, 0.811]\n","2024-09-25 19:31:28.953261: Epoch time: 22.64 s\n","2024-09-25 19:31:28.960199: Yayy! New best EMA pseudo Dice: 0.8212\n","2024-09-25 19:31:31.633602: \n","2024-09-25 19:31:31.637178: Epoch 62\n","2024-09-25 19:31:31.639693: Current learning rate: 0.00419\n","2024-09-25 19:31:54.226132: train_loss -0.7665\n","2024-09-25 19:31:54.236691: val_loss -0.7499\n","2024-09-25 19:31:54.244902: Pseudo dice [0.8584, 0.8731, 0.8461]\n","2024-09-25 19:31:54.254990: Epoch time: 22.59 s\n","2024-09-25 19:31:54.260969: Yayy! New best EMA pseudo Dice: 0.825\n","2024-09-25 19:31:56.960532: \n","2024-09-25 19:31:56.963503: Epoch 63\n","2024-09-25 19:31:56.965664: Current learning rate: 0.00409\n","2024-09-25 19:32:19.517230: train_loss -0.7621\n","2024-09-25 19:32:19.533932: val_loss -0.7727\n","2024-09-25 19:32:19.540259: Pseudo dice [0.8642, 0.8729, 0.8366]\n","2024-09-25 19:32:19.548792: Epoch time: 22.56 s\n","2024-09-25 19:32:19.556403: Yayy! New best EMA pseudo Dice: 0.8283\n","2024-09-25 19:32:21.940120: \n","2024-09-25 19:32:21.943010: Epoch 64\n","2024-09-25 19:32:21.946069: Current learning rate: 0.00399\n","2024-09-25 19:32:44.472756: train_loss -0.7736\n","2024-09-25 19:32:44.483007: val_loss -0.7222\n","2024-09-25 19:32:44.493459: Pseudo dice [0.792, 0.8719, 0.8359]\n","2024-09-25 19:32:44.503933: Epoch time: 22.53 s\n","2024-09-25 19:32:44.513312: Yayy! New best EMA pseudo Dice: 0.8288\n","2024-09-25 19:32:46.975219: \n","2024-09-25 19:32:46.977972: Epoch 65\n","2024-09-25 19:32:46.980939: Current learning rate: 0.00389\n","2024-09-25 19:33:09.624039: train_loss -0.7855\n","2024-09-25 19:33:09.635993: val_loss -0.7101\n","2024-09-25 19:33:09.663494: Pseudo dice [0.8067, 0.8634, 0.8031]\n","2024-09-25 19:33:09.672963: Epoch time: 22.65 s\n","2024-09-25 19:33:11.386925: \n","2024-09-25 19:33:11.389849: Epoch 66\n","2024-09-25 19:33:11.392981: Current learning rate: 0.00379\n","2024-09-25 19:33:33.988542: train_loss -0.7606\n","2024-09-25 19:33:33.994571: val_loss -0.7266\n","2024-09-25 19:33:34.001459: Pseudo dice [0.828, 0.8641, 0.8288]\n","2024-09-25 19:33:34.009790: Epoch time: 22.6 s\n","2024-09-25 19:33:34.016058: Yayy! New best EMA pseudo Dice: 0.8295\n","2024-09-25 19:33:36.419251: \n","2024-09-25 19:33:36.422598: Epoch 67\n","2024-09-25 19:33:36.425096: Current learning rate: 0.00369\n","2024-09-25 19:33:58.946388: train_loss -0.7875\n","2024-09-25 19:33:58.962417: val_loss -0.637\n","2024-09-25 19:33:58.968582: Pseudo dice [0.6786, 0.8422, 0.7228]\n","2024-09-25 19:33:58.977811: Epoch time: 22.53 s\n","2024-09-25 19:34:00.771323: \n","2024-09-25 19:34:00.774464: Epoch 68\n","2024-09-25 19:34:00.777398: Current learning rate: 0.00359\n","2024-09-25 19:34:23.332356: train_loss -0.7815\n","2024-09-25 19:34:23.341648: val_loss -0.6974\n","2024-09-25 19:34:23.357830: Pseudo dice [0.806, 0.8742, 0.7979]\n","2024-09-25 19:34:23.368428: Epoch time: 22.56 s\n","2024-09-25 19:34:25.130076: \n","2024-09-25 19:34:25.133347: Epoch 69\n","2024-09-25 19:34:25.135611: Current learning rate: 0.00349\n","2024-09-25 19:34:47.635807: train_loss -0.776\n","2024-09-25 19:34:47.653247: val_loss -0.6936\n","2024-09-25 19:34:47.659403: Pseudo dice [0.7898, 0.8748, 0.8036]\n","2024-09-25 19:34:47.667102: Epoch time: 22.51 s\n","2024-09-25 19:34:49.285712: \n","2024-09-25 19:34:49.289136: Epoch 70\n","2024-09-25 19:34:49.292566: Current learning rate: 0.00338\n","2024-09-25 19:35:11.832129: train_loss -0.7828\n","2024-09-25 19:35:11.850419: val_loss -0.7288\n","2024-09-25 19:35:11.859305: Pseudo dice [0.8286, 0.8648, 0.8361]\n","2024-09-25 19:35:11.865033: Epoch time: 22.55 s\n","2024-09-25 19:35:13.456734: \n","2024-09-25 19:35:13.459773: Epoch 71\n","2024-09-25 19:35:13.462014: Current learning rate: 0.00328\n","2024-09-25 19:35:36.030843: train_loss -0.7883\n","2024-09-25 19:35:36.035969: val_loss -0.7362\n","2024-09-25 19:35:36.057047: Pseudo dice [0.809, 0.8626, 0.832]\n","2024-09-25 19:35:36.062202: Epoch time: 22.58 s\n","2024-09-25 19:35:37.635949: \n","2024-09-25 19:35:37.638645: Epoch 72\n","2024-09-25 19:35:37.641805: Current learning rate: 0.00318\n","2024-09-25 19:36:00.194713: train_loss -0.7767\n","2024-09-25 19:36:00.202743: val_loss -0.7598\n","2024-09-25 19:36:00.211863: Pseudo dice [0.8631, 0.9003, 0.8267]\n","2024-09-25 19:36:00.218766: Epoch time: 22.56 s\n","2024-09-25 19:36:02.879793: \n","2024-09-25 19:36:02.883151: Epoch 73\n","2024-09-25 19:36:02.886749: Current learning rate: 0.00308\n","2024-09-25 19:36:25.523065: train_loss -0.7855\n","2024-09-25 19:36:25.528698: val_loss -0.6976\n","2024-09-25 19:36:25.535418: Pseudo dice [0.7795, 0.8728, 0.8051]\n","2024-09-25 19:36:25.541518: Epoch time: 22.65 s\n","2024-09-25 19:36:27.180784: \n","2024-09-25 19:36:27.183813: Epoch 74\n","2024-09-25 19:36:27.187282: Current learning rate: 0.00297\n","2024-09-25 19:36:49.749305: train_loss -0.7931\n","2024-09-25 19:36:49.754172: val_loss -0.6722\n","2024-09-25 19:36:49.757312: Pseudo dice [0.7506, 0.8424, 0.7586]\n","2024-09-25 19:36:49.762769: Epoch time: 22.57 s\n","2024-09-25 19:36:51.370267: \n","2024-09-25 19:36:51.386605: Epoch 75\n","2024-09-25 19:36:51.390116: Current learning rate: 0.00287\n","2024-09-25 19:37:13.958570: train_loss -0.7798\n","2024-09-25 19:37:13.965652: val_loss -0.6889\n","2024-09-25 19:37:13.971979: Pseudo dice [0.8375, 0.8626, 0.8095]\n","2024-09-25 19:37:13.977337: Epoch time: 22.59 s\n","2024-09-25 19:37:15.607186: \n","2024-09-25 19:37:15.623755: Epoch 76\n","2024-09-25 19:37:15.627228: Current learning rate: 0.00277\n","2024-09-25 19:37:38.175962: train_loss -0.781\n","2024-09-25 19:37:38.180266: val_loss -0.7167\n","2024-09-25 19:37:38.184955: Pseudo dice [0.8051, 0.8641, 0.7894]\n","2024-09-25 19:37:38.189663: Epoch time: 22.57 s\n","2024-09-25 19:37:39.785239: \n","2024-09-25 19:37:39.804009: Epoch 77\n","2024-09-25 19:37:39.807237: Current learning rate: 0.00266\n","2024-09-25 19:38:02.287538: train_loss -0.8017\n","2024-09-25 19:38:02.294845: val_loss -0.7385\n","2024-09-25 19:38:02.301884: Pseudo dice [0.8312, 0.881, 0.8104]\n","2024-09-25 19:38:02.308667: Epoch time: 22.5 s\n","2024-09-25 19:38:04.082741: \n","2024-09-25 19:38:04.086414: Epoch 78\n","2024-09-25 19:38:04.101776: Current learning rate: 0.00256\n","2024-09-25 19:38:26.714546: train_loss -0.7739\n","2024-09-25 19:38:26.720725: val_loss -0.7335\n","2024-09-25 19:38:26.728769: Pseudo dice [0.8385, 0.8532, 0.8305]\n","2024-09-25 19:38:26.739656: Epoch time: 22.63 s\n","2024-09-25 19:38:28.522368: \n","2024-09-25 19:38:28.525279: Epoch 79\n","2024-09-25 19:38:28.528404: Current learning rate: 0.00245\n","2024-09-25 19:38:51.161310: train_loss -0.7727\n","2024-09-25 19:38:51.167250: val_loss -0.748\n","2024-09-25 19:38:51.173125: Pseudo dice [0.8526, 0.8652, 0.8407]\n","2024-09-25 19:38:51.179924: Epoch time: 22.64 s\n","2024-09-25 19:38:51.185934: Yayy! New best EMA pseudo Dice: 0.83\n","2024-09-25 19:38:53.645383: \n","2024-09-25 19:38:53.648141: Epoch 80\n","2024-09-25 19:38:53.650377: Current learning rate: 0.00235\n","2024-09-25 19:39:16.523486: train_loss -0.7868\n","2024-09-25 19:39:16.528527: val_loss -0.7232\n","2024-09-25 19:39:16.534177: Pseudo dice [0.7952, 0.856, 0.8056]\n","2024-09-25 19:39:16.539531: Epoch time: 22.88 s\n","2024-09-25 19:39:18.199150: \n","2024-09-25 19:39:18.202804: Epoch 81\n","2024-09-25 19:39:18.206254: Current learning rate: 0.00224\n","2024-09-25 19:39:41.096456: train_loss -0.7928\n","2024-09-25 19:39:41.104059: val_loss -0.7\n","2024-09-25 19:39:41.113755: Pseudo dice [0.7991, 0.8621, 0.7748]\n","2024-09-25 19:39:41.121551: Epoch time: 22.9 s\n","2024-09-25 19:39:42.869386: \n","2024-09-25 19:39:42.872480: Epoch 82\n","2024-09-25 19:39:42.875877: Current learning rate: 0.00214\n","2024-09-25 19:40:05.645427: train_loss -0.7892\n","2024-09-25 19:40:05.653438: val_loss -0.6887\n","2024-09-25 19:40:05.660673: Pseudo dice [0.8249, 0.8707, 0.8069]\n","2024-09-25 19:40:05.668639: Epoch time: 22.78 s\n","2024-09-25 19:40:07.228842: \n","2024-09-25 19:40:07.231837: Epoch 83\n","2024-09-25 19:40:07.234869: Current learning rate: 0.00203\n","2024-09-25 19:40:29.901767: train_loss -0.7733\n","2024-09-25 19:40:29.909096: val_loss -0.7317\n","2024-09-25 19:40:29.913684: Pseudo dice [0.8217, 0.8639, 0.8357]\n","2024-09-25 19:40:29.918804: Epoch time: 22.67 s\n","2024-09-25 19:40:31.458276: \n","2024-09-25 19:40:31.461272: Epoch 84\n","2024-09-25 19:40:31.464481: Current learning rate: 0.00192\n","2024-09-25 19:40:54.063204: train_loss -0.7828\n","2024-09-25 19:40:54.072813: val_loss -0.7473\n","2024-09-25 19:40:54.080204: Pseudo dice [0.8429, 0.8778, 0.8331]\n","2024-09-25 19:40:54.088091: Epoch time: 22.61 s\n","2024-09-25 19:40:54.095531: Yayy! New best EMA pseudo Dice: 0.8313\n","2024-09-25 19:40:56.718570: \n","2024-09-25 19:40:56.721947: Epoch 85\n","2024-09-25 19:40:56.725528: Current learning rate: 0.00181\n","2024-09-25 19:41:19.398770: train_loss -0.7915\n","2024-09-25 19:41:19.405972: val_loss -0.7211\n","2024-09-25 19:41:19.411854: Pseudo dice [0.8142, 0.8805, 0.816]\n","2024-09-25 19:41:19.417903: Epoch time: 22.68 s\n","2024-09-25 19:41:19.424093: Yayy! New best EMA pseudo Dice: 0.8319\n","2024-09-25 19:41:21.862036: \n","2024-09-25 19:41:21.865250: Epoch 86\n","2024-09-25 19:41:21.868608: Current learning rate: 0.0017\n","2024-09-25 19:41:44.734626: train_loss -0.7807\n","2024-09-25 19:41:44.740319: val_loss -0.7919\n","2024-09-25 19:41:44.748355: Pseudo dice [0.8885, 0.8855, 0.8744]\n","2024-09-25 19:41:44.754875: Epoch time: 22.87 s\n","2024-09-25 19:41:44.765573: Yayy! New best EMA pseudo Dice: 0.837\n","2024-09-25 19:41:47.145358: \n","2024-09-25 19:41:47.148112: Epoch 87\n","2024-09-25 19:41:47.151048: Current learning rate: 0.00159\n","2024-09-25 19:42:09.714042: train_loss -0.7865\n","2024-09-25 19:42:09.731617: val_loss -0.7413\n","2024-09-25 19:42:09.737273: Pseudo dice [0.8552, 0.8766, 0.8406]\n","2024-09-25 19:42:09.743871: Epoch time: 22.57 s\n","2024-09-25 19:42:09.751172: Yayy! New best EMA pseudo Dice: 0.839\n","2024-09-25 19:42:12.566596: \n","2024-09-25 19:42:12.569645: Epoch 88\n","2024-09-25 19:42:12.573007: Current learning rate: 0.00148\n","2024-09-25 19:42:35.211970: train_loss -0.7862\n","2024-09-25 19:42:35.220793: val_loss -0.741\n","2024-09-25 19:42:35.228728: Pseudo dice [0.8578, 0.8856, 0.8141]\n","2024-09-25 19:42:35.236840: Epoch time: 22.65 s\n","2024-09-25 19:42:35.244540: Yayy! New best EMA pseudo Dice: 0.8404\n","2024-09-25 19:42:37.585761: \n","2024-09-25 19:42:38.147973: Epoch 89\n","2024-09-25 19:42:38.151469: Current learning rate: 0.00137\n","2024-09-25 19:43:00.962965: train_loss -0.7896\n","2024-09-25 19:43:00.969714: val_loss -0.7203\n","2024-09-25 19:43:00.979409: Pseudo dice [0.7994, 0.8658, 0.8037]\n","2024-09-25 19:43:00.985904: Epoch time: 23.38 s\n","2024-09-25 19:43:02.587211: \n","2024-09-25 19:43:02.590081: Epoch 90\n","2024-09-25 19:43:02.607861: Current learning rate: 0.00126\n","2024-09-25 19:43:25.278885: train_loss -0.7893\n","2024-09-25 19:43:25.288183: val_loss -0.7546\n","2024-09-25 19:43:25.294650: Pseudo dice [0.8559, 0.8945, 0.8488]\n","2024-09-25 19:43:25.300150: Epoch time: 22.69 s\n","2024-09-25 19:43:25.307475: Yayy! New best EMA pseudo Dice: 0.8414\n","2024-09-25 19:43:27.725853: \n","2024-09-25 19:43:27.729339: Epoch 91\n","2024-09-25 19:43:27.732054: Current learning rate: 0.00115\n","2024-09-25 19:43:50.286431: train_loss -0.7901\n","2024-09-25 19:43:50.297643: val_loss -0.7273\n","2024-09-25 19:43:50.307939: Pseudo dice [0.8187, 0.8693, 0.8253]\n","2024-09-25 19:43:50.318034: Epoch time: 22.56 s\n","2024-09-25 19:43:52.693460: \n","2024-09-25 19:43:52.696261: Epoch 92\n","2024-09-25 19:43:52.698355: Current learning rate: 0.00103\n","2024-09-25 19:44:15.370767: train_loss -0.7934\n","2024-09-25 19:44:15.374941: val_loss -0.732\n","2024-09-25 19:44:15.379360: Pseudo dice [0.8413, 0.8873, 0.8244]\n","2024-09-25 19:44:15.383277: Epoch time: 22.68 s\n","2024-09-25 19:44:15.399658: Yayy! New best EMA pseudo Dice: 0.842\n","2024-09-25 19:44:17.599842: \n","2024-09-25 19:44:17.602841: Epoch 93\n","2024-09-25 19:44:17.604988: Current learning rate: 0.00091\n","2024-09-25 19:44:40.208033: train_loss -0.798\n","2024-09-25 19:44:40.215261: val_loss -0.7157\n","2024-09-25 19:44:40.219986: Pseudo dice [0.8192, 0.8458, 0.7946]\n","2024-09-25 19:44:40.224534: Epoch time: 22.61 s\n","2024-09-25 19:44:41.821932: \n","2024-09-25 19:44:41.825373: Epoch 94\n","2024-09-25 19:44:41.828781: Current learning rate: 0.00079\n","2024-09-25 19:45:04.448836: train_loss -0.7927\n","2024-09-25 19:45:04.454649: val_loss -0.6826\n","2024-09-25 19:45:04.476884: Pseudo dice [0.7403, 0.8686, 0.7932]\n","2024-09-25 19:45:04.482023: Epoch time: 22.63 s\n","2024-09-25 19:45:06.035302: \n","2024-09-25 19:45:06.038216: Epoch 95\n","2024-09-25 19:45:06.041437: Current learning rate: 0.00067\n","2024-09-25 19:45:28.696382: train_loss -0.7955\n","2024-09-25 19:45:28.705676: val_loss -0.7714\n","2024-09-25 19:45:28.712155: Pseudo dice [0.8565, 0.8803, 0.8518]\n","2024-09-25 19:45:28.732356: Epoch time: 22.66 s\n","2024-09-25 19:45:30.358071: \n","2024-09-25 19:45:30.361115: Epoch 96\n","2024-09-25 19:45:30.364928: Current learning rate: 0.00055\n","2024-09-25 19:45:52.914265: train_loss -0.7868\n","2024-09-25 19:45:52.926140: val_loss -0.7129\n","2024-09-25 19:45:52.939848: Pseudo dice [0.7912, 0.8682, 0.7917]\n","2024-09-25 19:45:52.951061: Epoch time: 22.56 s\n","2024-09-25 19:45:54.667241: \n","2024-09-25 19:45:54.670216: Epoch 97\n","2024-09-25 19:45:54.673696: Current learning rate: 0.00043\n","2024-09-25 19:46:17.242420: train_loss -0.8012\n","2024-09-25 19:46:17.251953: val_loss -0.7038\n","2024-09-25 19:46:17.260067: Pseudo dice [0.8099, 0.871, 0.8065]\n","2024-09-25 19:46:17.282943: Epoch time: 22.58 s\n","2024-09-25 19:46:18.858030: \n","2024-09-25 19:46:18.860701: Epoch 98\n","2024-09-25 19:46:18.863707: Current learning rate: 0.0003\n","2024-09-25 19:46:41.475977: train_loss -0.8026\n","2024-09-25 19:46:41.480982: val_loss -0.7594\n","2024-09-25 19:46:41.487306: Pseudo dice [0.8656, 0.8775, 0.8406]\n","2024-09-25 19:46:41.495455: Epoch time: 22.62 s\n","2024-09-25 19:46:43.096073: \n","2024-09-25 19:46:43.098970: Epoch 99\n","2024-09-25 19:46:43.102159: Current learning rate: 0.00016\n","2024-09-25 19:47:05.772485: train_loss -0.8007\n","2024-09-25 19:47:05.777663: val_loss -0.7613\n","2024-09-25 19:47:05.782403: Pseudo dice [0.8495, 0.8756, 0.8428]\n","2024-09-25 19:47:05.787735: Epoch time: 22.68 s\n","2024-09-25 19:47:08.138862: Training done.\n","2024-09-25 19:47:08.211684: Using splits from existing split file: /content/drive/MyDrive/TCIA/nnUNet/nnUNet_preprocessed/Dataset501_Glioblastoma/splits_final.json\n","2024-09-25 19:47:08.218784: The split file contains 5 splits.\n","2024-09-25 19:47:08.222240: Desired fold for training: 0\n","2024-09-25 19:47:08.224979: This split has 74 training and 19 validation cases.\n","2024-09-25 19:47:08.228020: predicting 106\n","2024-09-25 19:47:08.271031: 106, shape torch.Size([4, 137, 160, 122]), rank 0\n","2024-09-25 19:47:33.669135: predicting 108\n","2024-09-25 19:47:34.623327: 108, shape torch.Size([4, 146, 177, 140]), rank 0\n","2024-09-25 19:47:45.632666: predicting 119\n","2024-09-25 19:47:45.651159: 119, shape torch.Size([4, 146, 167, 125]), rank 0\n","2024-09-25 19:47:47.495526: predicting 134\n","2024-09-25 19:47:47.516603: 134, shape torch.Size([4, 138, 167, 150]), rank 0\n","2024-09-25 19:47:51.141207: predicting 146\n","2024-09-25 19:47:51.158963: 146, shape torch.Size([4, 140, 170, 126]), rank 0\n","2024-09-25 19:47:53.017701: predicting 178\n","2024-09-25 19:47:53.037229: 178, shape torch.Size([4, 139, 168, 144]), rank 0\n","2024-09-25 19:47:56.726686: predicting 192\n","2024-09-25 19:47:56.762579: 192, shape torch.Size([4, 141, 174, 138]), rank 0\n","2024-09-25 19:48:00.437904: predicting 205\n","2024-09-25 19:48:00.459466: 205, shape torch.Size([4, 140, 158, 139]), rank 0\n","2024-09-25 19:48:04.133424: predicting 249\n","2024-09-25 19:48:04.155803: 249, shape torch.Size([4, 139, 176, 132]), rank 0\n","2024-09-25 19:48:07.826669: predicting 253\n","2024-09-25 19:48:07.844085: 253, shape torch.Size([4, 138, 166, 147]), rank 0\n","2024-09-25 19:48:11.486032: predicting 284\n","2024-09-25 19:48:11.504308: 284, shape torch.Size([4, 145, 168, 126]), rank 0\n","2024-09-25 19:48:13.366822: predicting 312\n","2024-09-25 19:48:13.389261: 312, shape torch.Size([4, 143, 173, 151]), rank 0\n","2024-09-25 19:48:17.070859: predicting 344\n","2024-09-25 19:48:17.091417: 344, shape torch.Size([4, 141, 173, 134]), rank 0\n","2024-09-25 19:48:21.167930: predicting 356\n","2024-09-25 19:48:21.186996: 356, shape torch.Size([4, 144, 173, 141]), rank 0\n","2024-09-25 19:48:24.815225: predicting 375\n","2024-09-25 19:48:24.831980: 375, shape torch.Size([4, 141, 175, 140]), rank 0\n","2024-09-25 19:48:28.399891: predicting 393\n","2024-09-25 19:48:28.415933: 393, shape torch.Size([4, 137, 159, 136]), rank 0\n","2024-09-25 19:48:31.976493: predicting 6\n","2024-09-25 19:48:31.993951: 6, shape torch.Size([4, 140, 188, 137]), rank 0\n","2024-09-25 19:48:35.536779: predicting 75\n","2024-09-25 19:48:35.555906: 75, shape torch.Size([4, 140, 171, 129]), rank 0\n","2024-09-25 19:48:39.088598: predicting 82\n","2024-09-25 19:48:39.105727: 82, shape torch.Size([4, 144, 188, 134]), rank 0\n","2024-09-25 19:48:53.634372: Validation complete\n","2024-09-25 19:48:53.637496: Mean Validation Dice:  0.7736619821908061\n"]}]},{"cell_type":"code","source":["!nnUNetv2_train Dataset501_Glioblastoma 3d_fullres 2 --npz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MmwVGtOov1Kh","executionInfo":{"status":"ok","timestamp":1728299778823,"user_tz":420,"elapsed":56593,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"1a1d109a-8357-465c-dede-0faa7442559c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","############################\n","INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","Using device: cuda:0\n","/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n","\n","#######################################################################\n","Please cite the following paper when using nnU-Net:\n","Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n","#######################################################################\n","\n","2024-10-06 22:45:08.354562: do_dummy_2d_data_aug: False\n","2024-10-06 22:45:08.553706: Using splits from existing split file: /content/drive/MyDrive/TCIA/nnUNet/nnUNet_preprocessed/Dataset501_Glioblastoma/splits_final.json\n","2024-10-06 22:45:08.979704: The split file contains 5 splits.\n","2024-10-06 22:45:08.982570: Desired fold for training: 2\n","2024-10-06 22:45:08.985395: This split has 74 training and 19 validation cases.\n","using pin_memory on device 0\n","using pin_memory on device 0\n","2024-10-06 22:45:35.185899: Using torch.compile...\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n","\n","This is the configuration used by this training:\n","Configuration name: 3d_fullres\n"," {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [140.0, 172.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n","\n","These are the global plan.json settings:\n"," {'dataset_name': 'Dataset501_Glioblastoma', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [140, 172, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1464.0, 'mean': 334.0672607421875, 'median': 326.0, 'min': 0.0, 'percentile_00_5': 133.0, 'percentile_99_5': 995.0, 'std': 99.8768310546875}, '1': {'max': 2347.0, 'mean': 433.7585754394531, 'median': 384.0, 'min': 0.0, 'percentile_00_5': 148.0, 'percentile_99_5': 1267.0, 'std': 191.0032501220703}, '2': {'max': 2957.0, 'mean': 545.624267578125, 'median': 521.0, 'min': 0.0, 'percentile_00_5': 75.0, 'percentile_99_5': 1584.0, 'std': 356.63787841796875}, '3': {'max': 1535.0, 'mean': 403.13323974609375, 'median': 384.0, 'min': 0.0, 'percentile_00_5': 110.0, 'percentile_99_5': 942.0, 'std': 145.57351684570312}}} \n","\n","2024-10-06 22:45:38.887068: unpacking dataset...\n","2024-10-06 22:45:45.787193: unpacking done...\n","2024-10-06 22:45:46.583877: Unable to plot network architecture: nnUNet_compile is enabled!\n","2024-10-06 22:45:46.600720: \n","2024-10-06 22:45:46.604716: Epoch 0\n","2024-10-06 22:45:46.610007: Current learning rate: 0.01\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n","    sys.exit(run_training_entry())\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 275, in run_training_entry\n","    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 211, in run_training\n","    nnunet_trainer.run_training()\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1370, in run_training\n","    train_outputs.append(self.train_step(next(self.dataloader_train)))\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 994, in train_step\n","    output = self.network(data)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/eval_frame.py\", line 433, in _fn\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n","    return self._call_impl(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n","    return forward_call(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 1116, in __call__\n","    return self._torchdynamo_orig_callable(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 948, in __call__\n","    result = self._inner_convert(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 472, in __call__\n","    return _compile(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_utils_internal.py\", line 84, in wrapper_function\n","    return StrobelightCompileTimeProfiler.profile_compile_time(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_strobelight/compile_time_profiler.py\", line 129, in profile_compile_time\n","    return func(*args, **kwargs)\n","  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n","    return func(*args, **kwds)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 817, in _compile\n","    guarded_code = compile_inner(code, one_graph, hooks, transform)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n","    r = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 636, in compile_inner\n","    out_code = transform_code_object(code, transform)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/bytecode_transformation.py\", line 1185, in transform_code_object\n","    transformations(instructions, code_options)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 178, in _fn\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/convert_frame.py\", line 582, in transform\n","    tracer.run()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2451, in run\n","    super().run()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 893, in run\n","    while self.step():\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 805, in step\n","    self.dispatch_table[inst.opcode](self, inst)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2642, in RETURN_VALUE\n","    self._return(inst)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/symbolic_convert.py\", line 2627, in _return\n","    self.output.compile_subgraph(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1123, in compile_subgraph\n","    self.compile_and_call_fx_graph(tx, pass2.graph_output_vars(), root)\n","  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n","    return func(*args, **kwds)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1318, in compile_and_call_fx_graph\n","    compiled_fn = self.call_user_compiler(gm)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n","    r = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1409, in call_user_compiler\n","    raise BackendCompilerFailed(self.compiler_fn, e).with_traceback(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/output_graph.py\", line 1390, in call_user_compiler\n","    compiled_fn = compiler_fn(gm, self.example_inputs())\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_dynamo.py\", line 129, in __call__\n","    compiled_gm = compiler_fn(gm, example_inputs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/__init__.py\", line 1951, in __call__\n","    return compile_fx(model_, inputs_, config_patches=self.config)\n","  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n","    return func(*args, **kwds)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1505, in compile_fx\n","    return aot_autograd(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/backends/common.py\", line 69, in __call__\n","    cg = aot_module_simplified(gm, example_inputs, **self.kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 954, in aot_module_simplified\n","    compiled_fn, _ = create_aot_dispatcher_function(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n","    r = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/aot_autograd.py\", line 687, in create_aot_dispatcher_function\n","    compiled_fn, fw_metadata = compiler_fn(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py\", line 461, in aot_dispatch_autograd\n","    compiled_fw_func = aot_config.fw_compiler(fw_module, adjusted_flat_args)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n","    r = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 1410, in fw_compiler_base\n","    return inner_compile(\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/repro/after_aot.py\", line 84, in debug_wrapper\n","    inner_compiled_fn = compiler_fn(gm, example_inputs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/debug.py\", line 304, in inner\n","    return fn(*args, **kwargs)\n","  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n","    return func(*args, **kwds)\n","  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n","    return func(*args, **kwds)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n","    r = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 527, in compile_fx_inner\n","    compiled_graph = fx_codegen_and_compile(\n","  File \"/usr/lib/python3.10/contextlib.py\", line 79, in inner\n","    return func(*args, **kwds)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/compile_fx.py\", line 831, in fx_codegen_and_compile\n","    compiled_fn = graph.compile_to_fn()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1751, in compile_to_fn\n","    return self.compile_to_module().call\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n","    r = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1680, in compile_to_module\n","    self.codegen_with_cpp_wrapper() if self.cpp_wrapper else self.codegen()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/graph.py\", line 1636, in codegen\n","    self.scheduler = Scheduler(self.buffers)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_dynamo/utils.py\", line 231, in time_wrapper\n","    r = func(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1364, in __init__\n","    self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1364, in <listcomp>\n","    self.nodes = [self.create_scheduler_node(n) for n in nodes]\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 1462, in create_scheduler_node\n","    return SchedulerNode(self, node)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 731, in __init__\n","    self._compute_attrs()\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 742, in _compute_attrs\n","    group_fn = self.scheduler.get_backend(self.node.get_device()).group_fn\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 2663, in get_backend\n","    self.backends[device] = self.create_backend(device)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/_inductor/scheduler.py\", line 2655, in create_backend\n","    raise RuntimeError(\n","torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:\n","RuntimeError: Cannot find a working triton installation. More information on installing Triton can be found at https://github.com/openai/triton\n","\n","Set TORCH_LOGS=\"+dynamo\" and TORCHDYNAMO_VERBOSE=1 for more information\n","\n","\n","You can suppress this exception and fall back to eager by setting:\n","    import torch._dynamo\n","    torch._dynamo.config.suppress_errors = True\n","\n","Exception in thread Thread-1 (results_loop):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 125, in results_loop\n","    raise e\n","  File \"/usr/local/lib/python3.10/dist-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 103, in results_loop\n","    raise RuntimeError(\"One or more background workers are no longer alive. Exiting. Please check the \"\n","RuntimeError: One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message\n","Exception in thread Thread-2 (results_loop):\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n","    self.run()\n","  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n","    self._target(*self._args, **self._kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 125, in results_loop\n","    raise e\n","  File \"/usr/local/lib/python3.10/dist-packages/batchgenerators/dataloading/nondet_multi_threaded_augmenter.py\", line 103, in results_loop\n","    raise RuntimeError(\"One or more background workers are no longer alive. Exiting. Please check the \"\n","RuntimeError: One or more background workers are no longer alive. Exiting. Please check the print statements above for the actual error message\n"]}]},{"cell_type":"code","source":["!nnUNetv2_predict -d Dataset501_Glioblastoma -i /content/drive/MyDrive/TCIA/nnUNet/nnUNet_raw/Dataset501_Glioblastoma/imagesTs -o /content/drive/MyDrive/TCIA/nnUNet/nnUNet_results/Dataset501_Glioblastoma/rest_9 -f  0 1  -tr nnUNetTrainer -c 3d_fullres -p nnUNetPlans"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SGXCK64BAnbB","executionInfo":{"status":"ok","timestamp":1748335352513,"user_tz":-330,"elapsed":189155,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"abda4f64-cab3-4b7d-8b9e-3712fe601b47"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","#######################################################################\n","Please cite the following paper when using nnU-Net:\n","Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n","#######################################################################\n","\n","There are 9 cases in the source folder\n","I am process 0 out of 1 (max process ID is 0, we start counting with 0!)\n","There are 9 cases that I would like to predict\n","\n","Predicting 122:\n","perform_everything_on_device: True\n","100% 8/8 [00:09<00:00,  1.14s/it]\n","100% 8/8 [00:06<00:00,  1.33it/s]\n","sending off prediction to background worker for resampling and export\n","done with 122\n","\n","Predicting 141:\n","perform_everything_on_device: True\n","100% 8/8 [00:06<00:00,  1.32it/s]\n","100% 8/8 [00:06<00:00,  1.32it/s]\n","sending off prediction to background worker for resampling and export\n","done with 141\n","\n","Predicting 307:\n","perform_everything_on_device: True\n","100% 8/8 [00:06<00:00,  1.31it/s]\n","100% 8/8 [00:06<00:00,  1.31it/s]\n","sending off prediction to background worker for resampling and export\n","done with 307\n","\n","Predicting 332:\n","perform_everything_on_device: True\n","100% 8/8 [00:06<00:00,  1.31it/s]\n","100% 8/8 [00:06<00:00,  1.30it/s]\n","sending off prediction to background worker for resampling and export\n","done with 332\n","\n","Predicting 352:\n","perform_everything_on_device: True\n","100% 8/8 [00:06<00:00,  1.29it/s]\n","100% 8/8 [00:06<00:00,  1.28it/s]\n","sending off prediction to background worker for resampling and export\n","done with 352\n","\n","Predicting 354:\n","perform_everything_on_device: True\n","100% 8/8 [00:06<00:00,  1.27it/s]\n","100% 8/8 [00:06<00:00,  1.27it/s]\n","sending off prediction to background worker for resampling and export\n","done with 354\n","\n","Predicting 614:\n","perform_everything_on_device: True\n","100% 8/8 [00:06<00:00,  1.27it/s]\n","100% 8/8 [00:06<00:00,  1.26it/s]\n","sending off prediction to background worker for resampling and export\n","done with 614\n","\n","Predicting 627:\n","perform_everything_on_device: True\n","100% 8/8 [00:06<00:00,  1.25it/s]\n","100% 8/8 [00:06<00:00,  1.25it/s]\n","sending off prediction to background worker for resampling and export\n","done with 627\n","\n","Predicting 86:\n","perform_everything_on_device: True\n","100% 8/8 [00:06<00:00,  1.24it/s]\n","100% 8/8 [00:06<00:00,  1.23it/s]\n","sending off prediction to background worker for resampling and export\n","done with 86\n"]}]},{"cell_type":"code","source":["!nnUNetv2_apply_postprocessing -i /content/drive/MyDrive/TCIA/nnUNet/nnUNet_results/Dataset501_Glioblastoma/inference -o /content/drive/MyDrive/TCIA/nnUNet/nnUNet_results/Dataset501_Glioblastoma/postprocessing -pp_pkl_file /content/drive/MyDrive/TCIA/nnUNet/nnUNet_results/Dataset501_Glioblastoma/nnUNetTrainer__nnUNetPlans__3d_fullres/crossval_results_folds_0_1/postprocessing.pkl -np 8 -plans_json /content/drive/MyDrive/TCIA/nnUNet/nnUNet_results/Dataset501_Glioblastoma/nnUNetTrainer__nnUNetPlans__3d_fullres/crossval_results_folds_0_1/plans.json"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kuBhR49gCryK","executionInfo":{"status":"ok","timestamp":1727299042183,"user_tz":-330,"elapsed":3424,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"4821b14b-7a15-41ea-ed22-54ee546259c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/local/bin/nnUNetv2_apply_postprocessing\", line 8, in <module>\n","    sys.exit(entry_point_apply_postprocessing())\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/postprocessing/remove_connected_components.py\", line 332, in entry_point_apply_postprocessing\n","    pp_fns, pp_fn_kwargs = load_pickle(args.pp_pkl_file)\n","  File \"/usr/local/lib/python3.10/dist-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n","    with open(file, mode) as f:\n","FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/TCIA/nnUNet/nnUNet_results/Dataset501_Glioblastoma/nnUNetTrainer__nnUNetPlans__3d_fullres/crossval_results_folds_0_1/postprocessing.pkl'\n"]}]}]}