{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","authorship_tag":"ABX9TyOwlXjqDrpns84cu7ziVsLn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6dX1hpNdhebx","executionInfo":{"status":"ok","timestamp":1727268538886,"user_tz":-330,"elapsed":27062,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"24667604-7da1-4541-b64d-7a8400628c08"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install nnunetv2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"O5LCDP0fi5CL","executionInfo":{"status":"ok","timestamp":1727268569634,"user_tz":-330,"elapsed":24089,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"c60dfd46-d0fa-4ba1-d4ec-d61ded500ce0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting nnunetv2\n","  Downloading nnunetv2-2.5.1.tar.gz (196 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/197.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/197.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.0/197.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2.4.1+cu121)\n","Collecting acvl-utils<0.3,>=0.2 (from nnunetv2)\n","  Downloading acvl_utils-0.2.tar.gz (18 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting dynamic-network-architectures<0.4,>=0.3.1 (from nnunetv2)\n","  Downloading dynamic_network_architectures-0.3.1.tar.gz (20 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (4.66.5)\n","Collecting dicom2nifti (from nnunetv2)\n","  Downloading dicom2nifti-2.4.11-py3-none-any.whl.metadata (1.3 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (1.13.1)\n","Collecting batchgenerators>=0.25 (from nnunetv2)\n","  Downloading batchgenerators-0.25.tar.gz (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (1.26.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (1.5.2)\n","Requirement already satisfied: scikit-image>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.24.0)\n","Collecting SimpleITK>=2.2.1 (from nnunetv2)\n","  Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2.1.4)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.20.3)\n","Requirement already satisfied: tifffile in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2024.9.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (2.32.3)\n","Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (5.2.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (3.7.1)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.13.1)\n","Collecting imagecodecs (from nnunetv2)\n","  Downloading imagecodecs-2024.9.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n","Collecting yacs (from nnunetv2)\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Collecting batchgeneratorsv2>=0.2 (from nnunetv2)\n","  Downloading batchgeneratorsv2-0.2.1.tar.gz (34 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from nnunetv2) (0.8.0)\n","Collecting connected-components-3d (from acvl-utils<0.3,>=0.2->nnunetv2)\n","  Downloading connected_components_3d-3.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2) (10.4.0)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2) (1.0.0)\n","Collecting unittest2 (from batchgenerators>=0.25->nnunetv2)\n","  Downloading unittest2-1.1.0-py2.py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (from batchgenerators>=0.25->nnunetv2) (3.5.0)\n","Collecting fft-conv-pytorch (from batchgeneratorsv2>=0.2->nnunetv2)\n","  Downloading fft_conv_pytorch-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n","Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2) (3.3)\n","Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2) (2.35.1)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2) (24.1)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.19.3->nnunetv2) (0.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (1.13.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->nnunetv2) (2024.6.1)\n","Collecting pydicom>=2.2.0 (from dicom2nifti->nnunetv2)\n","  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n","Collecting python-gdcm (from dicom2nifti->nnunetv2)\n","  Downloading python_gdcm-3.0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->nnunetv2) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->nnunetv2) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->nnunetv2) (2024.8.30)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->nnunetv2) (1.4.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from yacs->nnunetv2) (6.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->nnunetv2) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.2->nnunetv2) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.2->nnunetv2) (1.3.0)\n","Collecting argparse (from unittest2->batchgenerators>=0.25->nnunetv2)\n","  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n","Collecting traceback2 (from unittest2->batchgenerators>=0.25->nnunetv2)\n","  Downloading traceback2-1.4.0-py2.py3-none-any.whl.metadata (1.5 kB)\n","Collecting linecache2 (from traceback2->unittest2->batchgenerators>=0.25->nnunetv2)\n","  Downloading linecache2-1.0.0-py2.py3-none-any.whl.metadata (1000 bytes)\n","Downloading SimpleITK-2.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dicom2nifti-2.4.11-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading imagecodecs-2024.9.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading connected_components_3d-3.18.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading fft_conv_pytorch-1.2.0-py3-none-any.whl (6.8 kB)\n","Downloading python_gdcm-3.0.24.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading unittest2-1.1.0-py2.py3-none-any.whl (96 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n","Downloading traceback2-1.4.0-py2.py3-none-any.whl (16 kB)\n","Downloading linecache2-1.0.0-py2.py3-none-any.whl (12 kB)\n","Building wheels for collected packages: nnunetv2, acvl-utils, batchgenerators, batchgeneratorsv2, dynamic-network-architectures\n","  Building wheel for nnunetv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nnunetv2: filename=nnunetv2-2.5.1-py3-none-any.whl size=264366 sha256=1f14b09a095367d2238c5470b8bb82b2100712ef1e2a0cb4d034a2e296badd9c\n","  Stored in directory: /root/.cache/pip/wheels/5d/d6/90/88743b341922dc9f6795742570aac83a1eaa55f77ee676a5a6\n","  Building wheel for acvl-utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for acvl-utils: filename=acvl_utils-0.2-py3-none-any.whl size=22438 sha256=9543db90f2b2ca7303cbb5fa5b3b4a62f819013ef238ac9af639e5f1607b518c\n","  Stored in directory: /root/.cache/pip/wheels/ad/f0/84/52e8897591e66339bd2796681b9540b6c5e453c1461fa92a9e\n","  Building wheel for batchgenerators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for batchgenerators: filename=batchgenerators-0.25-py3-none-any.whl size=89008 sha256=5799f89315f5610a99ae04be6fd3ac541cbc18225f88f51efe537f938c523a40\n","  Stored in directory: /root/.cache/pip/wheels/9e/b0/1b/40912fb58eb167b86cbc444ddb2e6ba382b248215295f932e2\n","  Building wheel for batchgeneratorsv2 (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for batchgeneratorsv2: filename=batchgeneratorsv2-0.2.1-py3-none-any.whl size=45184 sha256=f53fa04234833f5c4c0d9af9165ee6e84116b061883f23f005ac11d966174591\n","  Stored in directory: /root/.cache/pip/wheels/a7/20/91/33993997db216e7b946d379850c47837d2478be49377a6cb41\n","  Building wheel for dynamic-network-architectures (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dynamic-network-architectures: filename=dynamic_network_architectures-0.3.1-py3-none-any.whl size=30049 sha256=286e347ad43ef20cf18df6a65a03f63be014867a2c5edb786c44522c9c5c4e01\n","  Stored in directory: /root/.cache/pip/wheels/55/1b/13/a6419c8dbf998b9343710355ec3edc5c8e24d9b7b22eec95fb\n","Successfully built nnunetv2 acvl-utils batchgenerators batchgeneratorsv2 dynamic-network-architectures\n","Installing collected packages: SimpleITK, linecache2, argparse, yacs, traceback2, python-gdcm, pydicom, imagecodecs, connected-components-3d, unittest2, dicom2nifti, fft-conv-pytorch, dynamic-network-architectures, batchgenerators, batchgeneratorsv2, acvl-utils, nnunetv2\n","Successfully installed SimpleITK-2.4.0 acvl-utils-0.2 argparse-1.4.0 batchgenerators-0.25 batchgeneratorsv2-0.2.1 connected-components-3d-3.18.0 dicom2nifti-2.4.11 dynamic-network-architectures-0.3.1 fft-conv-pytorch-1.2.0 imagecodecs-2024.9.22 linecache2-1.0.0 nnunetv2-2.5.1 pydicom-3.0.1 python-gdcm-3.0.24.1 traceback2-1.4.0 unittest2-1.1.0 yacs-0.1.8\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]},"id":"8cd949e04b2b4f3095fb40f66a0e126b"}},"metadata":{}}]},{"cell_type":"code","source":["!pip install --upgrade git+https://github.com/FabianIsensee/hiddenlayer.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-KgZSByEjeUY","executionInfo":{"status":"ok","timestamp":1727268615920,"user_tz":-330,"elapsed":5939,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"6292a40b-b1d7-45ee-d6ce-ca0f1c79c2e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/FabianIsensee/hiddenlayer.git\n","  Cloning https://github.com/FabianIsensee/hiddenlayer.git to /tmp/pip-req-build-is7mtpqw\n","  Running command git clone --filter=blob:none --quiet https://github.com/FabianIsensee/hiddenlayer.git /tmp/pip-req-build-is7mtpqw\n","  Resolved https://github.com/FabianIsensee/hiddenlayer.git to commit b7263b6dc4569da1b6dea5964e1eac78fa32fa77\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: hiddenlayer\n","  Building wheel for hiddenlayer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hiddenlayer: filename=hiddenlayer-0.2-py3-none-any.whl size=20003 sha256=ce8d3b91f56ba0c25224726e9929ac3972e22add5a67f51b4fd2c652d6ccd8da\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-d_woxbp2/wheels/55/0e/e3/fdf2f92789305c0e320e0ab01f27fd4b757b1bb01c07d532c4\n","Successfully built hiddenlayer\n","Installing collected packages: hiddenlayer\n","Successfully installed hiddenlayer-0.2\n"]}]},{"cell_type":"code","source":["!pip install triton"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WbvJSqphZJFQ","outputId":"9486e09f-f184-4441-827a-91f0fedaa321"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting triton\n","  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n","Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton\n"]}]},{"cell_type":"code","source":["!export TORCH_LOGS=\"+dynamo\"\n","!export TORCHDYNAMO_VERBOSE=1"],"metadata":{"id":"xaIZSoJ0ZY1M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.environ['nnUNet_raw'] = \"/content/drive/MyDrive/TCIA/nnUNet/nnUNet_raw\"\n","os.environ['nnUNet_preprocessed'] =  \"/content/drive/MyDrive/TCIA/nnUNet/nnUNet_preprocessed\"\n","os.environ['nnUNet_results'] = \"/content/drive/MyDrive/TCIA/nnUNet/nnUNet_results\"\n","!nnUNetv2_train Dataset501_Glioblastoma 3d_fullres 2 --npz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WRyLC8QuB1Jz","executionInfo":{"status":"ok","timestamp":1727278478526,"user_tz":-330,"elapsed":9818621,"user":{"displayName":"DEV DEVESWAR RANA","userId":"10892359940652001245"}},"outputId":"5d7445d6-9f97-48a7-d476-613a25bbe879"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","############################\n","INFO: You are using the old nnU-Net default plans. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n","############################\n","\n","Using device: cuda:0\n","/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py:164: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.grad_scaler = GradScaler() if self.device.type == 'cuda' else None\n","\n","#######################################################################\n","Please cite the following paper when using nnU-Net:\n","Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.\n","#######################################################################\n","\n","2024-09-25 12:50:58.966671: do_dummy_2d_data_aug: False\n","2024-09-25 12:50:58.972069: Creating new 5-fold cross-validation split...\n","2024-09-25 12:50:58.981022: Desired fold for training: 0\n","2024-09-25 12:50:58.983486: This split has 74 training and 19 validation cases.\n","using pin_memory on device 0\n","using pin_memory on device 0\n","2024-09-25 12:51:12.014023: Using torch.compile...\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\n","\n","This is the configuration used by this training:\n","Configuration name: 3d_fullres\n"," {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [140.0, 172.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}, 'deep_supervision': True}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} \n","\n","These are the global plan.json settings:\n"," {'dataset_name': 'Dataset501_Glioblastoma', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [140, 172, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 1464.0, 'mean': 334.0672607421875, 'median': 326.0, 'min': 0.0, 'percentile_00_5': 133.0, 'percentile_99_5': 995.0, 'std': 99.8768310546875}, '1': {'max': 2347.0, 'mean': 433.7585754394531, 'median': 384.0, 'min': 0.0, 'percentile_00_5': 148.0, 'percentile_99_5': 1267.0, 'std': 191.0032501220703}, '2': {'max': 2957.0, 'mean': 545.624267578125, 'median': 521.0, 'min': 0.0, 'percentile_00_5': 75.0, 'percentile_99_5': 1584.0, 'std': 356.63787841796875}, '3': {'max': 1535.0, 'mean': 403.13323974609375, 'median': 384.0, 'min': 0.0, 'percentile_00_5': 110.0, 'percentile_99_5': 942.0, 'std': 145.57351684570312}}} \n","\n","2024-09-25 12:51:15.800495: unpacking dataset...\n","2024-09-25 12:51:55.425659: unpacking done...\n","2024-09-25 12:51:56.130667: Unable to plot network architecture: nnUNet_compile is enabled!\n","2024-09-25 12:51:56.161230: \n","2024-09-25 12:51:56.164403: Epoch 0\n","2024-09-25 12:51:56.167851: Current learning rate: 0.01\n","W0925 12:52:12.996000 135711805448192 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:13.166000 135711805448192 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:13.244000 135711805448192 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:13.324000 135711805448192 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:13.407000 135711805448192 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:30.237000 135711805448192 torch/fx/experimental/symbolic_shapes.py:4449] [1/1] ps0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:36.078000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] d0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:36.482000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] d0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:36.764000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] d0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:37.055000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] d0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:38.466000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] d0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:39.761000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:39.818000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:40.298000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:40.357000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:40.642000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:40.701000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:40.965000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:41.020000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:42.636000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] q0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:42.763000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] z0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:43.768000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:44.077000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:44.270000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:44.459000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x0 is not in var_ranges, defaulting to unknown range.\n","W0925 12:52:45.326000 135707438585408 torch/fx/experimental/symbolic_shapes.py:4449] [0/0] x1 is not in var_ranges, defaulting to unknown range.\n","W0925 12:55:38.775000 135711805448192 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 12:55:38.890000 135711805448192 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 12:55:38.953000 135711805448192 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 12:55:39.015000 135711805448192 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 12:55:39.078000 135711805448192 torch/fx/experimental/symbolic_shapes.py:4449] [0/1] xindex is not in var_ranges, defaulting to unknown range.\n","W0925 12:55:46.664000 135711805448192 torch/fx/experimental/symbolic_shapes.py:4449] [1/2] ps0 is not in var_ranges, defaulting to unknown range.\n","2024-09-25 12:55:57.807418: train_loss -0.3042\n","2024-09-25 12:55:57.811708: val_loss -0.4542\n","2024-09-25 12:55:57.815542: Pseudo dice [0.5005, 0.7054, 0.6948]\n","2024-09-25 12:55:57.818940: Epoch time: 241.65 s\n","2024-09-25 12:55:57.822558: Yayy! New best EMA pseudo Dice: 0.6336\n","2024-09-25 12:55:59.650926: \n","2024-09-25 12:55:59.654130: Epoch 1\n","2024-09-25 12:55:59.657457: Current learning rate: 0.00999\n","2024-09-25 12:58:44.176382: train_loss -0.5859\n","2024-09-25 12:58:44.180512: val_loss -0.578\n","2024-09-25 12:58:44.184199: Pseudo dice [0.7204, 0.7693, 0.71]\n","2024-09-25 12:58:44.202554: Epoch time: 164.53 s\n","2024-09-25 12:58:44.204794: Yayy! New best EMA pseudo Dice: 0.6435\n","2024-09-25 12:58:46.176430: \n","2024-09-25 12:58:46.179395: Epoch 2\n","2024-09-25 12:58:46.181665: Current learning rate: 0.00998\n","2024-09-25 13:01:30.281690: train_loss -0.649\n","2024-09-25 13:01:30.286831: val_loss -0.6396\n","2024-09-25 13:01:30.291599: Pseudo dice [0.7404, 0.8314, 0.7933]\n","2024-09-25 13:01:30.313951: Epoch time: 164.11 s\n","2024-09-25 13:01:30.318041: Yayy! New best EMA pseudo Dice: 0.658\n","2024-09-25 13:01:32.447346: \n","2024-09-25 13:01:32.450562: Epoch 3\n","2024-09-25 13:01:32.454443: Current learning rate: 0.00997\n","2024-09-25 13:04:16.996442: train_loss -0.6883\n","2024-09-25 13:04:17.000974: val_loss -0.6206\n","2024-09-25 13:04:17.005065: Pseudo dice [0.6794, 0.8174, 0.727]\n","2024-09-25 13:04:17.008628: Epoch time: 164.55 s\n","2024-09-25 13:04:17.011936: Yayy! New best EMA pseudo Dice: 0.6663\n","2024-09-25 13:04:19.297275: \n","2024-09-25 13:04:19.300185: Epoch 4\n","2024-09-25 13:04:19.303531: Current learning rate: 0.00996\n","2024-09-25 13:07:03.544648: train_loss -0.7084\n","2024-09-25 13:07:03.549105: val_loss -0.6611\n","2024-09-25 13:07:03.554195: Pseudo dice [0.7288, 0.8238, 0.7865]\n","2024-09-25 13:07:03.558882: Epoch time: 164.25 s\n","2024-09-25 13:07:03.563355: Yayy! New best EMA pseudo Dice: 0.6777\n","2024-09-25 13:07:06.316041: \n","2024-09-25 13:07:06.318973: Epoch 5\n","2024-09-25 13:07:06.322302: Current learning rate: 0.00995\n","2024-09-25 13:09:50.338097: train_loss -0.7303\n","2024-09-25 13:09:50.342340: val_loss -0.7179\n","2024-09-25 13:09:50.346189: Pseudo dice [0.8016, 0.8541, 0.8206]\n","2024-09-25 13:09:50.349560: Epoch time: 164.02 s\n","2024-09-25 13:09:50.367003: Yayy! New best EMA pseudo Dice: 0.6925\n","2024-09-25 13:09:52.402936: \n","2024-09-25 13:09:52.406229: Epoch 6\n","2024-09-25 13:09:52.410015: Current learning rate: 0.00995\n","2024-09-25 13:12:36.631772: train_loss -0.7383\n","2024-09-25 13:12:36.636156: val_loss -0.6721\n","2024-09-25 13:12:36.640445: Pseudo dice [0.7691, 0.8629, 0.781]\n","2024-09-25 13:12:36.644361: Epoch time: 164.23 s\n","2024-09-25 13:12:36.647611: Yayy! New best EMA pseudo Dice: 0.7036\n","2024-09-25 13:12:38.724276: \n","2024-09-25 13:12:38.727269: Epoch 7\n","2024-09-25 13:12:38.730220: Current learning rate: 0.00994\n","2024-09-25 13:15:22.549229: train_loss -0.7429\n","2024-09-25 13:15:22.553060: val_loss -0.6815\n","2024-09-25 13:15:22.557195: Pseudo dice [0.7869, 0.8707, 0.7883]\n","2024-09-25 13:15:22.561486: Epoch time: 163.83 s\n","2024-09-25 13:15:22.565088: Yayy! New best EMA pseudo Dice: 0.7148\n","2024-09-25 13:15:24.616468: \n","2024-09-25 13:15:24.619186: Epoch 8\n","2024-09-25 13:15:24.621296: Current learning rate: 0.00993\n","2024-09-25 13:18:09.504905: train_loss -0.7436\n","2024-09-25 13:18:09.509158: val_loss -0.6822\n","2024-09-25 13:18:09.513855: Pseudo dice [0.7787, 0.8647, 0.7794]\n","2024-09-25 13:18:09.518508: Epoch time: 164.89 s\n","2024-09-25 13:18:09.522996: Yayy! New best EMA pseudo Dice: 0.7241\n","2024-09-25 13:18:11.746645: \n","2024-09-25 13:18:11.749398: Epoch 9\n","2024-09-25 13:18:11.751360: Current learning rate: 0.00992\n","2024-09-25 13:20:56.384008: train_loss -0.7492\n","2024-09-25 13:20:56.389076: val_loss -0.6772\n","2024-09-25 13:20:56.393640: Pseudo dice [0.7317, 0.8579, 0.7522]\n","2024-09-25 13:20:56.398702: Epoch time: 164.64 s\n","2024-09-25 13:20:56.404092: Yayy! New best EMA pseudo Dice: 0.7297\n","2024-09-25 13:20:58.521197: \n","2024-09-25 13:20:58.524431: Epoch 10\n","2024-09-25 13:20:58.527456: Current learning rate: 0.00991\n","2024-09-25 13:23:43.210945: train_loss -0.7549\n","2024-09-25 13:23:43.215480: val_loss -0.6897\n","2024-09-25 13:23:43.233056: Pseudo dice [0.7739, 0.8541, 0.8015]\n","2024-09-25 13:23:43.236799: Epoch time: 164.69 s\n","2024-09-25 13:23:43.240859: Yayy! New best EMA pseudo Dice: 0.7377\n","2024-09-25 13:23:45.446415: \n","2024-09-25 13:23:45.449070: Epoch 11\n","2024-09-25 13:23:45.452226: Current learning rate: 0.0099\n","2024-09-25 13:26:29.989065: train_loss -0.7691\n","2024-09-25 13:26:29.993395: val_loss -0.6868\n","2024-09-25 13:26:29.997408: Pseudo dice [0.7833, 0.8587, 0.8062]\n","2024-09-25 13:26:30.000768: Epoch time: 164.54 s\n","2024-09-25 13:26:30.004502: Yayy! New best EMA pseudo Dice: 0.7456\n","2024-09-25 13:26:32.036553: \n","2024-09-25 13:26:32.039423: Epoch 12\n","2024-09-25 13:26:32.041633: Current learning rate: 0.00989\n","2024-09-25 13:29:16.754114: train_loss -0.77\n","2024-09-25 13:29:16.758273: val_loss -0.7307\n","2024-09-25 13:29:16.762501: Pseudo dice [0.8296, 0.8543, 0.8268]\n","2024-09-25 13:29:16.766772: Epoch time: 164.72 s\n","2024-09-25 13:29:16.770683: Yayy! New best EMA pseudo Dice: 0.7547\n","2024-09-25 13:29:18.966253: \n","2024-09-25 13:29:18.969396: Epoch 13\n","2024-09-25 13:29:18.972704: Current learning rate: 0.00988\n","2024-09-25 13:32:03.567345: train_loss -0.7782\n","2024-09-25 13:32:03.571905: val_loss -0.6681\n","2024-09-25 13:32:03.575620: Pseudo dice [0.7243, 0.8557, 0.7956]\n","2024-09-25 13:32:03.592128: Epoch time: 164.6 s\n","2024-09-25 13:32:03.595560: Yayy! New best EMA pseudo Dice: 0.7584\n","2024-09-25 13:32:05.726914: \n","2024-09-25 13:32:05.730207: Epoch 14\n","2024-09-25 13:32:05.732541: Current learning rate: 0.00987\n","2024-09-25 13:34:50.517815: train_loss -0.7722\n","2024-09-25 13:34:50.521180: val_loss -0.7143\n","2024-09-25 13:34:50.524795: Pseudo dice [0.8287, 0.8704, 0.8104]\n","2024-09-25 13:34:50.527244: Epoch time: 164.79 s\n","2024-09-25 13:34:50.530405: Yayy! New best EMA pseudo Dice: 0.7662\n","2024-09-25 13:34:52.614386: \n","2024-09-25 13:34:52.617190: Epoch 15\n","2024-09-25 13:34:52.620382: Current learning rate: 0.00986\n","2024-09-25 13:37:37.517864: train_loss -0.7702\n","2024-09-25 13:37:37.522326: val_loss -0.687\n","2024-09-25 13:37:37.526236: Pseudo dice [0.7555, 0.8602, 0.7738]\n","2024-09-25 13:37:37.529674: Epoch time: 164.9 s\n","2024-09-25 13:37:37.532978: Yayy! New best EMA pseudo Dice: 0.7693\n","2024-09-25 13:37:39.622441: \n","2024-09-25 13:37:39.626031: Epoch 16\n","2024-09-25 13:37:39.628449: Current learning rate: 0.00986\n","2024-09-25 13:40:24.832601: train_loss -0.7792\n","2024-09-25 13:40:24.849879: val_loss -0.7116\n","2024-09-25 13:40:24.854723: Pseudo dice [0.8079, 0.8717, 0.8122]\n","2024-09-25 13:40:24.859344: Epoch time: 165.21 s\n","2024-09-25 13:40:24.863904: Yayy! New best EMA pseudo Dice: 0.7754\n","2024-09-25 13:40:27.901835: \n","2024-09-25 13:40:27.904753: Epoch 17\n","2024-09-25 13:40:27.907870: Current learning rate: 0.00985\n","2024-09-25 13:43:13.247854: train_loss -0.7828\n","2024-09-25 13:43:13.251936: val_loss -0.723\n","2024-09-25 13:43:13.255958: Pseudo dice [0.8037, 0.8718, 0.8182]\n","2024-09-25 13:43:13.259995: Epoch time: 165.35 s\n","2024-09-25 13:43:13.264085: Yayy! New best EMA pseudo Dice: 0.781\n","2024-09-25 13:43:15.354255: \n","2024-09-25 13:43:15.369908: Epoch 18\n","2024-09-25 13:43:15.373521: Current learning rate: 0.00984\n","2024-09-25 13:46:00.868796: train_loss -0.7839\n","2024-09-25 13:46:00.872050: val_loss -0.7218\n","2024-09-25 13:46:00.875012: Pseudo dice [0.8371, 0.862, 0.8226]\n","2024-09-25 13:46:00.877928: Epoch time: 165.52 s\n","2024-09-25 13:46:00.879929: Yayy! New best EMA pseudo Dice: 0.7869\n","2024-09-25 13:46:02.927323: \n","2024-09-25 13:46:02.929937: Epoch 19\n","2024-09-25 13:46:02.932670: Current learning rate: 0.00983\n","2024-09-25 13:48:48.645528: train_loss -0.7829\n","2024-09-25 13:48:48.649205: val_loss -0.7357\n","2024-09-25 13:48:48.652540: Pseudo dice [0.8356, 0.877, 0.8088]\n","2024-09-25 13:48:48.656248: Epoch time: 165.72 s\n","2024-09-25 13:48:48.660305: Yayy! New best EMA pseudo Dice: 0.7923\n","2024-09-25 13:48:51.297643: \n","2024-09-25 13:48:51.300576: Epoch 20\n","2024-09-25 13:48:51.302611: Current learning rate: 0.00982\n","2024-09-25 13:51:36.789485: train_loss -0.7903\n","2024-09-25 13:51:36.794573: val_loss -0.7207\n","2024-09-25 13:51:36.799537: Pseudo dice [0.8059, 0.8748, 0.8178]\n","2024-09-25 13:51:36.804305: Epoch time: 165.49 s\n","2024-09-25 13:51:36.809674: Yayy! New best EMA pseudo Dice: 0.7963\n","2024-09-25 13:51:39.036775: \n","2024-09-25 13:51:39.040061: Epoch 21\n","2024-09-25 13:51:39.044199: Current learning rate: 0.00981\n","2024-09-25 13:54:24.387223: train_loss -0.7883\n","2024-09-25 13:54:24.391712: val_loss -0.7157\n","2024-09-25 13:54:24.395746: Pseudo dice [0.8355, 0.8632, 0.8227]\n","2024-09-25 13:54:24.400825: Epoch time: 165.35 s\n","2024-09-25 13:54:24.405337: Yayy! New best EMA pseudo Dice: 0.8008\n","2024-09-25 13:54:26.617855: \n","2024-09-25 13:54:26.621249: Epoch 22\n","2024-09-25 13:54:26.625087: Current learning rate: 0.0098\n","2024-09-25 13:57:11.988149: train_loss -0.7901\n","2024-09-25 13:57:11.992035: val_loss -0.6965\n","2024-09-25 13:57:11.996477: Pseudo dice [0.7837, 0.865, 0.8144]\n","2024-09-25 13:57:12.000847: Epoch time: 165.37 s\n","2024-09-25 13:57:12.004556: Yayy! New best EMA pseudo Dice: 0.8028\n","2024-09-25 13:57:14.741161: \n","2024-09-25 13:57:14.744495: Epoch 23\n","2024-09-25 13:57:14.747224: Current learning rate: 0.00979\n","2024-09-25 14:00:00.193874: train_loss -0.7883\n","2024-09-25 14:00:00.198338: val_loss -0.7499\n","2024-09-25 14:00:00.202389: Pseudo dice [0.8247, 0.8756, 0.8382]\n","2024-09-25 14:00:00.207262: Epoch time: 165.45 s\n","2024-09-25 14:00:00.211347: Yayy! New best EMA pseudo Dice: 0.8071\n","2024-09-25 14:00:02.319859: \n","2024-09-25 14:00:02.322629: Epoch 24\n","2024-09-25 14:00:02.953443: Current learning rate: 0.00978\n","2024-09-25 14:02:49.130413: train_loss -0.789\n","2024-09-25 14:02:49.134296: val_loss -0.7104\n","2024-09-25 14:02:49.138784: Pseudo dice [0.807, 0.8525, 0.7919]\n","2024-09-25 14:02:49.143384: Epoch time: 166.81 s\n","2024-09-25 14:02:49.148076: Yayy! New best EMA pseudo Dice: 0.8081\n","2024-09-25 14:02:51.286261: \n","2024-09-25 14:02:51.289087: Epoch 25\n","2024-09-25 14:02:51.292495: Current learning rate: 0.00977\n","2024-09-25 14:05:37.394902: train_loss -0.7843\n","2024-09-25 14:05:37.400311: val_loss -0.7166\n","2024-09-25 14:05:37.406042: Pseudo dice [0.8117, 0.8676, 0.8151]\n","2024-09-25 14:05:37.411186: Epoch time: 166.11 s\n","2024-09-25 14:05:37.416789: Yayy! New best EMA pseudo Dice: 0.8105\n","2024-09-25 14:05:39.584312: \n","2024-09-25 14:05:39.587227: Epoch 26\n","2024-09-25 14:05:39.589588: Current learning rate: 0.00977\n","2024-09-25 14:08:25.893682: train_loss -0.7874\n","2024-09-25 14:08:25.897756: val_loss -0.72\n","2024-09-25 14:08:25.902211: Pseudo dice [0.7917, 0.8694, 0.8169]\n","2024-09-25 14:08:25.905934: Epoch time: 166.31 s\n","2024-09-25 14:08:25.910416: Yayy! New best EMA pseudo Dice: 0.812\n","2024-09-25 14:08:27.987915: \n","2024-09-25 14:08:27.990700: Epoch 27\n","2024-09-25 14:08:27.992806: Current learning rate: 0.00976\n","2024-09-25 14:11:13.703188: train_loss -0.7929\n","2024-09-25 14:11:13.706595: val_loss -0.7155\n","2024-09-25 14:11:13.709934: Pseudo dice [0.8061, 0.8567, 0.8151]\n","2024-09-25 14:11:13.726250: Epoch time: 165.72 s\n","2024-09-25 14:11:13.729479: Yayy! New best EMA pseudo Dice: 0.8134\n","2024-09-25 14:11:15.776895: \n","2024-09-25 14:11:15.779735: Epoch 28\n","2024-09-25 14:11:15.782224: Current learning rate: 0.00975\n","2024-09-25 14:14:01.488070: train_loss -0.7984\n","2024-09-25 14:14:01.492953: val_loss -0.7361\n","2024-09-25 14:14:01.497331: Pseudo dice [0.8374, 0.871, 0.8164]\n","2024-09-25 14:14:01.500979: Epoch time: 165.71 s\n","2024-09-25 14:14:01.504338: Yayy! New best EMA pseudo Dice: 0.8162\n","2024-09-25 14:14:04.162230: \n","2024-09-25 14:14:04.164933: Epoch 29\n","2024-09-25 14:14:04.167930: Current learning rate: 0.00974\n","2024-09-25 14:16:49.754060: train_loss -0.8028\n","2024-09-25 14:16:49.757949: val_loss -0.756\n","2024-09-25 14:16:49.761940: Pseudo dice [0.8459, 0.8988, 0.84]\n","2024-09-25 14:16:49.765027: Epoch time: 165.59 s\n","2024-09-25 14:16:49.768801: Yayy! New best EMA pseudo Dice: 0.8208\n","2024-09-25 14:16:51.807398: \n","2024-09-25 14:16:51.810526: Epoch 30\n","2024-09-25 14:16:51.812632: Current learning rate: 0.00973\n","2024-09-25 14:19:37.407832: train_loss -0.8019\n","2024-09-25 14:19:37.412663: val_loss -0.6972\n","2024-09-25 14:19:37.417029: Pseudo dice [0.7902, 0.8795, 0.7847]\n","2024-09-25 14:19:37.420703: Epoch time: 165.6 s\n","2024-09-25 14:19:38.835720: \n","2024-09-25 14:19:38.839360: Epoch 31\n","2024-09-25 14:19:38.855640: Current learning rate: 0.00972\n","2024-09-25 14:22:22.274569: train_loss -0.8035\n","2024-09-25 14:22:22.278379: val_loss -0.7224\n","2024-09-25 14:22:22.282425: Pseudo dice [0.8087, 0.872, 0.8019]\n","2024-09-25 14:22:22.286369: Epoch time: 163.44 s\n","2024-09-25 14:22:22.290169: Yayy! New best EMA pseudo Dice: 0.8212\n","2024-09-25 14:22:24.311377: \n","2024-09-25 14:22:24.314202: Epoch 32\n","2024-09-25 14:22:24.317365: Current learning rate: 0.00971\n","2024-09-25 14:25:10.791890: train_loss -0.8024\n","2024-09-25 14:25:10.797178: val_loss -0.7686\n","2024-09-25 14:25:10.817617: Pseudo dice [0.8849, 0.8975, 0.8341]\n","2024-09-25 14:25:10.822029: Epoch time: 166.48 s\n","2024-09-25 14:25:10.826178: Yayy! New best EMA pseudo Dice: 0.8263\n","2024-09-25 14:25:13.017413: \n","2024-09-25 14:25:13.020112: Epoch 33\n","2024-09-25 14:25:13.023316: Current learning rate: 0.0097\n","2024-09-25 14:27:57.185664: train_loss -0.7985\n","2024-09-25 14:27:57.189139: val_loss -0.7281\n","2024-09-25 14:27:57.192517: Pseudo dice [0.8354, 0.8796, 0.8175]\n","2024-09-25 14:27:57.194769: Epoch time: 164.17 s\n","2024-09-25 14:27:57.198182: Yayy! New best EMA pseudo Dice: 0.8281\n","2024-09-25 14:27:59.369992: \n","2024-09-25 14:27:59.373650: Epoch 34\n","2024-09-25 14:27:59.377508: Current learning rate: 0.00969\n","2024-09-25 14:30:44.674442: train_loss -0.8066\n","2024-09-25 14:30:44.678460: val_loss -0.7586\n","2024-09-25 14:30:44.682926: Pseudo dice [0.8526, 0.8813, 0.828]\n","2024-09-25 14:30:44.687632: Epoch time: 165.31 s\n","2024-09-25 14:30:44.691902: Yayy! New best EMA pseudo Dice: 0.8307\n","2024-09-25 14:30:46.934581: \n","2024-09-25 14:30:46.937977: Epoch 35\n","2024-09-25 14:30:46.940264: Current learning rate: 0.00968\n","2024-09-25 14:33:29.697240: train_loss -0.8081\n","2024-09-25 14:33:29.713378: val_loss -0.7238\n","2024-09-25 14:33:29.717140: Pseudo dice [0.8176, 0.8607, 0.819]\n","2024-09-25 14:33:29.720664: Epoch time: 162.76 s\n","2024-09-25 14:33:29.723972: Yayy! New best EMA pseudo Dice: 0.8308\n","2024-09-25 14:33:32.643854: \n","2024-09-25 14:33:32.647365: Epoch 36\n","2024-09-25 14:33:32.649784: Current learning rate: 0.00968\n","2024-09-25 14:36:18.039155: train_loss -0.8147\n","2024-09-25 14:36:18.043386: val_loss -0.6733\n","2024-09-25 14:36:18.047953: Pseudo dice [0.7525, 0.8736, 0.8012]\n","2024-09-25 14:36:18.052361: Epoch time: 165.4 s\n","2024-09-25 14:36:19.497030: \n","2024-09-25 14:36:19.500433: Epoch 37\n","2024-09-25 14:36:19.503705: Current learning rate: 0.00967\n","2024-09-25 14:39:04.484961: train_loss -0.8081\n","2024-09-25 14:39:04.488998: val_loss -0.7193\n","2024-09-25 14:39:04.492983: Pseudo dice [0.8201, 0.8705, 0.8207]\n","2024-09-25 14:39:04.496635: Epoch time: 164.99 s\n","2024-09-25 14:39:05.945843: \n","2024-09-25 14:39:05.948493: Epoch 38\n","2024-09-25 14:39:05.950512: Current learning rate: 0.00966\n","2024-09-25 14:41:51.328378: train_loss -0.8007\n","2024-09-25 14:41:51.331680: val_loss -0.7817\n","2024-09-25 14:41:51.335577: Pseudo dice [0.8645, 0.8932, 0.8508]\n","2024-09-25 14:41:51.339627: Epoch time: 165.38 s\n","2024-09-25 14:41:51.342103: Yayy! New best EMA pseudo Dice: 0.8335\n","2024-09-25 14:41:53.481768: \n","2024-09-25 14:41:53.485074: Epoch 39\n","2024-09-25 14:41:53.487445: Current learning rate: 0.00965\n","2024-09-25 14:44:39.048968: train_loss -0.8027\n","2024-09-25 14:44:39.052969: val_loss -0.6962\n","2024-09-25 14:44:39.056355: Pseudo dice [0.7687, 0.8653, 0.7831]\n","2024-09-25 14:44:39.060209: Epoch time: 165.57 s\n","2024-09-25 14:44:40.561294: \n","2024-09-25 14:44:40.573622: Epoch 40\n","2024-09-25 14:44:40.577156: Current learning rate: 0.00964\n","2024-09-25 14:47:25.914144: train_loss -0.8027\n","2024-09-25 14:47:25.917328: val_loss -0.7309\n","2024-09-25 14:47:25.920429: Pseudo dice [0.8156, 0.869, 0.832]\n","2024-09-25 14:47:25.923505: Epoch time: 165.35 s\n","2024-09-25 14:47:27.388477: \n","2024-09-25 14:47:27.391456: Epoch 41\n","2024-09-25 14:47:27.393538: Current learning rate: 0.00963\n","2024-09-25 14:50:12.262148: train_loss -0.8101\n","2024-09-25 14:50:12.266243: val_loss -0.6624\n","2024-09-25 14:50:12.270425: Pseudo dice [0.7254, 0.8368, 0.7627]\n","2024-09-25 14:50:12.274487: Epoch time: 164.87 s\n","2024-09-25 14:50:13.755341: \n","2024-09-25 14:50:13.758538: Epoch 42\n","2024-09-25 14:50:13.761612: Current learning rate: 0.00962\n","2024-09-25 14:52:59.894693: train_loss -0.8128\n","2024-09-25 14:52:59.898812: val_loss -0.7113\n","2024-09-25 14:52:59.902969: Pseudo dice [0.7934, 0.866, 0.8118]\n","2024-09-25 14:52:59.906480: Epoch time: 166.14 s\n","2024-09-25 14:53:01.306406: \n","2024-09-25 14:53:01.309825: Epoch 43\n","2024-09-25 14:53:01.313643: Current learning rate: 0.00961\n","2024-09-25 14:55:47.433590: train_loss -0.8164\n","2024-09-25 14:55:47.437776: val_loss -0.735\n","2024-09-25 14:55:47.442245: Pseudo dice [0.7895, 0.8637, 0.8261]\n","2024-09-25 14:55:47.445146: Epoch time: 166.13 s\n","2024-09-25 14:55:48.871666: \n","2024-09-25 14:55:48.874599: Epoch 44\n","2024-09-25 14:55:48.877130: Current learning rate: 0.0096\n","2024-09-25 14:58:34.891986: train_loss -0.8209\n","2024-09-25 14:58:34.910448: val_loss -0.7273\n","2024-09-25 14:58:34.914955: Pseudo dice [0.7941, 0.8595, 0.8161]\n","2024-09-25 14:58:34.919071: Epoch time: 166.02 s\n","2024-09-25 14:58:36.382292: \n","2024-09-25 14:58:36.385632: Epoch 45\n","2024-09-25 14:58:36.388929: Current learning rate: 0.00959\n","2024-09-25 15:01:22.110739: train_loss -0.8137\n","2024-09-25 15:01:22.114866: val_loss -0.7525\n","2024-09-25 15:01:22.119378: Pseudo dice [0.8109, 0.8826, 0.8414]\n","2024-09-25 15:01:22.124017: Epoch time: 165.73 s\n","2024-09-25 15:01:23.534161: \n","2024-09-25 15:01:23.546539: Epoch 46\n","2024-09-25 15:01:23.550218: Current learning rate: 0.00959\n","2024-09-25 15:04:09.816467: train_loss -0.8163\n","2024-09-25 15:04:09.819931: val_loss -0.7227\n","2024-09-25 15:04:09.824152: Pseudo dice [0.8089, 0.8733, 0.8064]\n","2024-09-25 15:04:09.827839: Epoch time: 166.28 s\n","2024-09-25 15:04:11.244349: \n","2024-09-25 15:04:11.247064: Epoch 47\n","2024-09-25 15:04:11.250058: Current learning rate: 0.00958\n","2024-09-25 15:06:57.178062: train_loss -0.8187\n","2024-09-25 15:06:57.182416: val_loss -0.7711\n","2024-09-25 15:06:57.185144: Pseudo dice [0.8651, 0.8856, 0.8486]\n","2024-09-25 15:06:57.188381: Epoch time: 165.93 s\n","2024-09-25 15:06:58.593589: \n","2024-09-25 15:06:58.596461: Epoch 48\n","2024-09-25 15:06:58.599669: Current learning rate: 0.00957\n","2024-09-25 15:09:44.742267: train_loss -0.8214\n","2024-09-25 15:09:44.746340: val_loss -0.7189\n","2024-09-25 15:09:44.750573: Pseudo dice [0.817, 0.8606, 0.8018]\n","2024-09-25 15:09:44.754671: Epoch time: 166.15 s\n","2024-09-25 15:09:46.263291: \n","2024-09-25 15:09:46.266066: Epoch 49\n","2024-09-25 15:09:46.269161: Current learning rate: 0.00956\n","2024-09-25 15:12:32.408242: train_loss -0.8197\n","2024-09-25 15:12:32.412451: val_loss -0.6701\n","2024-09-25 15:12:32.417079: Pseudo dice [0.6978, 0.8618, 0.7696]\n","2024-09-25 15:12:32.420959: Epoch time: 166.15 s\n","2024-09-25 15:12:34.525774: \n","2024-09-25 15:12:34.528967: Epoch 50\n","2024-09-25 15:12:34.531914: Current learning rate: 0.00955\n","2024-09-25 15:15:20.896286: train_loss -0.8176\n","2024-09-25 15:15:20.900540: val_loss -0.7564\n","2024-09-25 15:15:20.906091: Pseudo dice [0.8208, 0.8783, 0.828]\n","2024-09-25 15:15:20.910634: Epoch time: 166.37 s\n","2024-09-25 15:15:22.416430: \n","2024-09-25 15:15:22.419661: Epoch 51\n","2024-09-25 15:15:22.423252: Current learning rate: 0.00954\n","2024-09-25 15:18:09.184826: train_loss -0.8135\n","2024-09-25 15:18:09.188912: val_loss -0.7202\n","2024-09-25 15:18:09.192947: Pseudo dice [0.7831, 0.8664, 0.8137]\n","2024-09-25 15:18:09.197489: Epoch time: 166.77 s\n","2024-09-25 15:18:10.591830: \n","2024-09-25 15:18:10.594692: Epoch 52\n","2024-09-25 15:18:10.612354: Current learning rate: 0.00953\n","2024-09-25 15:20:57.095710: train_loss -0.8243\n","2024-09-25 15:20:57.099871: val_loss -0.7333\n","2024-09-25 15:20:57.104510: Pseudo dice [0.8089, 0.8763, 0.8248]\n","2024-09-25 15:20:57.108820: Epoch time: 166.51 s\n","2024-09-25 15:20:58.511683: \n","2024-09-25 15:20:58.514577: Epoch 53\n","2024-09-25 15:20:58.516615: Current learning rate: 0.00952\n","2024-09-25 15:23:44.789398: train_loss -0.8176\n","2024-09-25 15:23:44.792681: val_loss -0.7669\n","2024-09-25 15:23:44.808977: Pseudo dice [0.841, 0.8687, 0.8515]\n","2024-09-25 15:23:44.812394: Epoch time: 166.28 s\n","2024-09-25 15:23:46.243158: \n","2024-09-25 15:23:46.246582: Epoch 54\n","2024-09-25 15:23:46.250450: Current learning rate: 0.00951\n","2024-09-25 15:26:32.274135: train_loss -0.8206\n","2024-09-25 15:26:32.278802: val_loss -0.7509\n","2024-09-25 15:26:32.283577: Pseudo dice [0.8496, 0.8727, 0.8324]\n","2024-09-25 15:26:32.288196: Epoch time: 166.03 s\n","2024-09-25 15:26:34.512261: \n","2024-09-25 15:26:34.515466: Epoch 55\n","2024-09-25 15:26:34.519014: Current learning rate: 0.0095\n","2024-09-25 15:29:20.414021: train_loss -0.8169\n","2024-09-25 15:29:20.417400: val_loss -0.7172\n","2024-09-25 15:29:20.421230: Pseudo dice [0.7839, 0.8572, 0.8206]\n","2024-09-25 15:29:20.437775: Epoch time: 165.9 s\n","2024-09-25 15:29:21.821232: \n","2024-09-25 15:29:21.824159: Epoch 56\n","2024-09-25 15:29:21.827285: Current learning rate: 0.00949\n","2024-09-25 15:32:07.584526: train_loss -0.8149\n","2024-09-25 15:32:07.587986: val_loss -0.7497\n","2024-09-25 15:32:07.591677: Pseudo dice [0.8123, 0.8726, 0.8404]\n","2024-09-25 15:32:07.594584: Epoch time: 165.76 s\n","2024-09-25 15:32:09.001941: \n","2024-09-25 15:32:09.005153: Epoch 57\n","2024-09-25 15:32:09.007643: Current learning rate: 0.00949\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/nnUNetv2_train\", line 8, in <module>\n","    sys.exit(run_training_entry())\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 275, in run_training_entry\n","    run_training(args.dataset_name_or_id, args.configuration, args.fold, args.tr, args.p, args.pretrained_weights,\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/run/run_training.py\", line 211, in run_training\n","    nnunet_trainer.run_training()\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1370, in run_training\n","    train_outputs.append(self.train_step(next(self.dataloader_train)))\n","  File \"/usr/local/lib/python3.10/dist-packages/nnunetv2/training/nnUNetTrainer/nnUNetTrainer.py\", line 1002, in train_step\n","    self.grad_scaler.step(self.optimizer)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\", line 454, in step\n","    retval = self._maybe_opt_step(optimizer, optimizer_state, *args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\", line 351, in _maybe_opt_step\n","    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\", line 351, in <genexpr>\n","    if not sum(v.item() for v in optimizer_state[\"found_inf_per_device\"].values()):\n","KeyboardInterrupt\n"]}]}]}